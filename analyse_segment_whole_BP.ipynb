{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sys, importlib\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "\n",
    "import skimage.measure\n",
    "import scipy\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "from utils import circular_mean, circular_variance\n",
    "\n",
    "from generic import load_image, save_image\n",
    "importlib.reload(sys.modules['generic'])\n",
    "\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "import matplotlib.font_manager\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.context('seaborn-paper')\n",
    "# plt.style.use('seaborn-notebook')\n",
    "# plt.style.use('seaborn-poster')\n",
    "# plt.style.use('seaborn-talk')\n",
    "set_matplotlib_formats('svg')\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "\n",
    "linewidth = 0.25\n",
    "titlesize = 'medium'\n",
    "labelsize = 'small'\n",
    "ticksize = 'x-small'\n",
    "\n",
    "markersize = 10\n",
    "scattersize = 5\n",
    "\n",
    "palette_stages='gist_heat'\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': [5.9/2, 5.9/2 * 2/3],\n",
    "\n",
    "    'text.usetex': False,\n",
    "    'font.size': 10,\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': 'Helvetica',\n",
    "\n",
    "    'figure.titlesize': titlesize,\n",
    "    'legend.title_fontsize': labelsize,\n",
    "    'legend.fontsize': ticksize,\n",
    "    'axes.labelsize': labelsize,\n",
    "    'xtick.labelsize': ticksize,\n",
    "    'ytick.labelsize': ticksize,\n",
    "    'ytick.labelsize': ticksize,\n",
    "\n",
    "    'figure.autolayout': False,\n",
    "\n",
    "    'axes.linewidth': linewidth,\n",
    "    'xtick.major.width': linewidth,\n",
    "    'xtick.minor.width': 0.8*linewidth,\n",
    "    'ytick.major.width': linewidth,\n",
    "    'ytick.minor.width': 0.8*linewidth,\n",
    "    'grid.linewidth': linewidth,\n",
    "\n",
    "    'patch.linewidth': linewidth,\n",
    "\n",
    "    'lines.markersize': scattersize\n",
    "})\n",
    "\n",
    "    \n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "matplotlib.font_manager.findSystemFonts(fontpaths='/usr/share/fonts/truetype', fontext='ttf')\n",
    "font_manager.findfont('Helvetica', fallback_to_default=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and segmentations\n",
    "Images = dict()\n",
    "Originals = dict()\n",
    "\n",
    "basepath = '/home/julian/image_analysis'\n",
    "path = 'data/whole_BP'\n",
    "\n",
    "figure_path = 'analysis/1_figures'\n",
    "figure_path = os.path.abspath(os.path.join(basepath, figure_path))\n",
    "filenames = []\n",
    "for filename in os.listdir(os.path.join(basepath, path)):\n",
    "    f = os.path.join(os.path.join(basepath, path), filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        filenames.append(filename)\n",
    "\n",
    "filenames = [\n",
    "    ('E8/1_max_projection/E8_sample_1.tif', 'E8/1_max_projection/E8_sample_1__probability.tif'),\n",
    "    ('E8/1_max_projection/E8_sample_2.tif', 'E8/1_max_projection/E8_sample_2__probability.tif'),\n",
    "\n",
    "    ('E10/1_max_projection/E10_sample_2.tif', 'E10/1_max_projection/E10_sample_2__probability.tif'),\n",
    "    ('E10_2025/3_cleaning/E10_2.tif', 'E10_2025/3_cleaning/E10_2__probability.tif'),\n",
    "    ('E10_2025/3_cleaning/E10_3.tif', 'E10_2025/3_cleaning/E10_3__probability.tif'),\n",
    "    # ('E10_2025/3_cleaning/E10_4.tif', 'E10_2025/3_cleaning/E10_4__probability.tif'),\n",
    "\n",
    "    ('E12/1_max_projection/E12_sample_1.tif', 'E12/1_max_projection/E12_sample_1__probability.tif'),\n",
    "    ('E12/1_max_projection/E12_sample_2.tif', 'E12/1_max_projection/E12_sample_2__probability.tif'),\n",
    "    ('E12/1_max_projection/E12_sample_3.tif', 'E12/1_max_projection/E12_sample_3__probability.tif'),\n",
    "    \n",
    "    ('E14_2025/3_cleaning/E14_1.tif', 'E14_2025/3_cleaning/E14_1__probability.tif'),\n",
    "    ('E14_2025/3_cleaning/E14_2.tif', 'E14_2025/3_cleaning/E14_2__probability.tif'),\n",
    "    ('E14_2025/3_cleaning/E14_3.tif', 'E14_2025/3_cleaning/E14_3__probability.tif'),\n",
    "]\n",
    "# filenames = [f for f in filenames if f[-4:] == '.tif']\n",
    "print(filenames)\n",
    "\n",
    "for filename in filenames:\n",
    "    if type(filename) is str:\n",
    "        original = filename\n",
    "    else:\n",
    "        original = filename[0]\n",
    "        if len(filename) > 1:\n",
    "            filename = filename[1]\n",
    "        else:\n",
    "            filename = original\n",
    "    print(filename, original)\n",
    "\n",
    "    log.info(\"Loading image and segmentation to {} ...\".format(filename))\n",
    "    # continue\n",
    "\n",
    "    Images[original] = load_image(\n",
    "        base_dir = basepath,\n",
    "        in_dir=path,\n",
    "        filename=filename,\n",
    "        dims=['y', 'x'],\n",
    "        normalise=True,\n",
    "        logger=log\n",
    "    ).squeeze()\n",
    "    Originals[original] = load_image(\n",
    "        base_dir = basepath,\n",
    "        in_dir=path,\n",
    "        filename=original,\n",
    "        dims=['y', 'x'],\n",
    "        normalise=True,\n",
    "        logger=log\n",
    "    ).squeeze()\n",
    "\n",
    "filenames = Images.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_background(image, radius=50, light_bg=False):\n",
    "    from skimage.morphology import white_tophat, black_tophat, disk\n",
    "    str_el = disk(radius) #you can also use 'ball' here to get a slightly smoother result at the cost of increased computing time\n",
    "    if light_bg:\n",
    "        return xr.DataArray(black_tophat(image, str_el), coords=image.coords)\n",
    "    else:\n",
    "        return xr.DataArray(white_tophat(image, str_el), coords=image.coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment HCs\n",
    "watershed on distance map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode_label_interfaces(labels):\n",
    "    labels[1:,:] = labels[1:,:].where(~np.multiply(labels.data[1:,:]!=labels.data[:-1,:], labels.data[:-1,:]>0), 0)\n",
    "    # labels[:-1,:] = labels[:-1,:].where((__labels[:-1,:]==__labels[1:,:]) and (__labels[1:,:] > 0), 0)\n",
    "    labels[:,1:] = labels[:,1:].where(~np.multiply(labels.data[:,1:]!=labels.data[:,:-1], labels.data[:,:-1] > 0), 0)\n",
    "    # labels[:,:-1] = labels[:,:-1].where((__labels[:,:-1]==__labels[:,1:]) and (__labels[:,1:] > 0), 0)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_cells(labels, *, voronoi=None, exclude_distance=2., minimum_area=5):\n",
    "    res_x = labels.attrs.get('resolution_x', np.nan)\n",
    "    res_y = labels.attrs.get('resolution_y', np.nan)\n",
    "    res_z = labels.attrs.get('resolution_z', np.nan)\n",
    "\n",
    "    objects = pd.DataFrame()\n",
    "    objects['filename'] = None\n",
    "    objects['stage'] = None\n",
    "    objects['id'] = np.unique(labels)[1:]\n",
    "    bincount = np.bincount(labels.data.flatten())\n",
    "    objects['area_pixels'] = np.asarray([bincount[id] for id in objects['id']])\n",
    "    objects['area_um2'] = objects['area_pixels'] / res_x / res_y\n",
    "    objects['center_pixels'] = scipy.ndimage.measurements.center_of_mass(labels, labels=labels, index=objects['id'])\n",
    "    objects['center_x_pixels'] = objects['center_pixels'].apply(lambda xy: int(np.round(xy[0])))\n",
    "    objects['center_y_pixels'] = objects['center_pixels'].apply(lambda xy: int(np.round(xy[1])))\n",
    "    objects['center_x_um'] = objects['center_x_pixels'] / res_x\n",
    "    objects['center_y_um'] = objects['center_y_pixels'] / res_y\n",
    "\n",
    "    # Excluding cells outside 2 sigma from local average area\n",
    "    print(f\"  Excluding cells outside {exclude_distance} sigma from local average area.\")\n",
    "    distance = scipy.spatial.distance_matrix(\n",
    "        objects[['center_x_pixels', 'center_y_pixels']],\n",
    "        objects[['center_x_pixels', 'center_y_pixels']]\n",
    "    )\n",
    "    distance_mask = distance < 500\n",
    "\n",
    "    i = 0\n",
    "    for index, row in objects.iterrows():\n",
    "        objects.loc[index, 'local_area_pixel'] = objects.loc[distance_mask[i], 'area_pixels'].mean()\n",
    "        objects.loc[index, 'local_area_pixel__std'] = objects.loc[distance_mask[i], 'area_pixels'].std()\n",
    "        i += 1\n",
    "\n",
    "    objects['exclude'] = (\n",
    "          (objects['area_pixels'] < objects['local_area_pixel'] - exclude_distance * objects['local_area_pixel__std'])\n",
    "        | (objects['area_pixels'] < minimum_area)\n",
    "        # | (objects['area_pixels'] > objects['local_area_pixel'] + exclude_distance * objects['local_area_pixel__std'])\n",
    "    )\n",
    "\n",
    "    objects['filename'] = labels.attrs.get('filename', None)\n",
    "    objects['stage'] = objects['filename'].apply(lambda s: s.split('_')[0])\n",
    "    objects = objects.set_index(objects['id'])\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = dict()\n",
    "Coords = dict()\n",
    "Voronoi = dict()\n",
    "\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    \n",
    "    if 'z' in Images[filename].dims: \n",
    "        image = Images[filename].max(dim='z')\n",
    "    else:\n",
    "        image = Images[filename]\n",
    "    img = image.data\n",
    "    # img = skimage.filters.gaussian(img, sigma=0.5)\n",
    "    N = 1\n",
    "    while image.shape[0]/N > 2000:\n",
    "        N += 1\n",
    "    if N == 1:\n",
    "        overlap = 0\n",
    "    else:\n",
    "        overlap = 200\n",
    "    print(f\"Splitting image ({image.shape[0]}x{image.shape[1]}) into {N} chunks with {overlap} pixels overlap\")\n",
    "\n",
    "    equalize= np.linspace(12, 10, N)\n",
    "    peak_distance = np.linspace(8, 4, N)\n",
    "    # peak_distance = np.linspace(8, 4, N) # E8 / E10 / E12\n",
    "    if N == 1:\n",
    "        equalize = [10]\n",
    "        peak_distance = [10]\n",
    "\n",
    "    __labels = xr.zeros_like(image, dtype=int)\n",
    "    __voronoi = xr.zeros_like(image, dtype=int)\n",
    "    markers = xr.zeros_like(image, dtype=int)\n",
    "    distance = xr.zeros_like(image, dtype=int)\n",
    "\n",
    "    # thresh = skimage.filters.threshold_otsu(image.data)\n",
    "    # __bw = np.where(image > thresh/1.3, 1, 0)\n",
    "    \n",
    "    __bw = np.where(image > 0.7, 1, 0)\n",
    "    # __bw = np.where(image > 0.1, 1, 0) # E10 / E12\n",
    "    __bw = skimage.morphology.binary_dilation(__bw)\n",
    "\n",
    "    for chunk in range(N):\n",
    "    # for chunk in range(1,2):\n",
    "        print(f\"   Processing chunk {chunk+1}/{N} ...\")\n",
    "        Lx = image.shape[0]\n",
    "        min_x = max(int(chunk/N*Lx-overlap/2), 0)\n",
    "        max_x = min(int((chunk+1)/N*Lx+overlap/2), Lx)\n",
    "        img = image.data[min_x:max_x,:]\n",
    "\n",
    "        img = skimage.filters.gaussian(img, sigma=0.5)\n",
    "        # img = skimage.morphology.white_tophat(img, skimage.morphology.disk(equalize[chunk]))\n",
    "        # img = skimage.exposure.equalize_adapthist(img, kernel_size=equalize[chunk], clip_limit=0.01)\n",
    "\n",
    "\n",
    "        bw = __bw[min_x:max_x].copy()\n",
    "        bw[0,:] = 1\n",
    "        bw[bw.shape[0]-1,:] = 1\n",
    "        bw[:,0] = 1\n",
    "        bw[:,bw.shape[1]-1] = 1\n",
    "        bw = skimage.segmentation.flood_fill(bw, (0,0), 0)\n",
    "\n",
    "        _distance = scipy.ndimage.distance_transform_edt(bw)\n",
    "\n",
    "        coords = skimage.feature.peak_local_max(_distance, labels=bw, min_distance=int(peak_distance[chunk]))\n",
    "        mask = np.zeros(img.shape, dtype=bool)\n",
    "        mask[tuple(coords.T)] = True\n",
    "\n",
    "        _markers, _ = scipy.ndimage.label(mask)\n",
    "\n",
    "        _labels = np.zeros_like(img, dtype=int) + skimage.segmentation.watershed(-_distance, _markers, mask=bw)\n",
    "        _voronoi = np.zeros_like(img, dtype=int) + skimage.segmentation.watershed(-_distance, _markers, mask=img)\n",
    "\n",
    "        _labels = np.where(_labels > 0, _labels + __labels.max().data, 0)\n",
    "        _voronoi = np.where(_voronoi > 0, _voronoi + __voronoi.max().data, 0)\n",
    "\n",
    "        __labels[min_x:max_x,:] = np.where(__labels[min_x:max_x,:]==0, _labels, __labels[min_x:max_x,:])\n",
    "        __voronoi[min_x:max_x,:] = np.where(__voronoi[min_x:max_x,:]==0, _voronoi, __voronoi[min_x:max_x,:])\n",
    "        markers[min_x:max_x,:] = np.where(markers[min_x:max_x,:]==0, _markers, markers[min_x:max_x,:])\n",
    "        distance[min_x:max_x,:] = np.where(distance[min_x:max_x,:]==0, _distance, distance[min_x:max_x,:])\n",
    "    print(f\"   Done.\")\n",
    "\n",
    "    labels = xr.zeros_like(__labels) + __labels\n",
    "    voronoi = xr.zeros_like(__voronoi) + __voronoi\n",
    "    ids = np.unique(__labels)[1:]\n",
    "    # if np.unique(__voronoi)[1:].shape[0] != ids.shape[0]:\n",
    "    #     raise\n",
    "\n",
    "    # np.random.shuffle(ids)\n",
    "    # for i, rid in enumerate(ids):\n",
    "    #     labels = np.where(__labels==i+1, rid, labels)\n",
    "    #     voronoi = np.where(__voronoi==i+1, rid, voronoi)\n",
    "\n",
    "    labels = xr.zeros_like(image, dtype=int) + erode_label_interfaces(labels)\n",
    "    voronoi = xr.zeros_like(image, dtype=int) + voronoi\n",
    "    markers = xr.zeros_like(image, dtype=bool) + markers > 0\n",
    "    distance = xr.zeros_like(image) + distance\n",
    "    labels.attrs = image.attrs\n",
    "    voronoi.attrs = image.attrs\n",
    "    markers.attrs = image.attrs\n",
    "    distance.attrs = image.attrs\n",
    "\n",
    "    # Labels[filename] = labels\n",
    "    # Coords[filename] = coords\n",
    "    # Voronoi[filename] = voronoi\n",
    "\n",
    "    objects = measure_cells(labels, exclude_distance=5, minimum_area=50)\n",
    "    cnt_exclude = objects['exclude'].count()\n",
    "    print(f'Found {cnt_exclude} cells in {filename}.')\n",
    "    \n",
    "    cnt_exclude = objects['exclude'].sum()\n",
    "    print(f'Excluding {cnt_exclude} cells based on local 2 std area criterion.')\n",
    "\n",
    "    for id in objects.loc[objects['exclude'], 'id']:\n",
    "        labels = labels.where(labels!=id, 0)\n",
    "\n",
    "    # Labels[filename] = labels\n",
    "    # Coords[filename] = coords\n",
    "    # Voronoi[filename] = voronoi\n",
    "\n",
    "    print(f'Identified {np.unique(labels).shape[0]-1} cells in {filename}.')\n",
    "\n",
    "    if filename in Originals.keys():\n",
    "        original = Originals[filename]\n",
    "    else:\n",
    "        original = Images[filename]\n",
    "    tmp = xr.concat([original, labels.where(labels==0, labels % 20 + 1)], dim='c').assign_coords(c=[0,1])\n",
    "    tmp.attrs = image.attrs\n",
    "\n",
    "    filename_raw = filename.split('/')[-1].split('.')[0]\n",
    "    out_dir = os.path.join(basepath, path)\n",
    "    for p in  filename.split('/')[:-1]:\n",
    "        out_dir = os.path.join(out_dir, p)\n",
    "    out_dir = os.path.join(out_dir, filename_raw)\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    if not 'stage' in objects.columns:\n",
    "        objects['stage'] = filename.split('/')[0].split('_')[0]\n",
    "        print(objects['stage'])\n",
    "\n",
    "    print(f\"Saving result ...\")\n",
    "    objects.to_csv(os.path.join(out_dir, f\"{filename_raw}.csv\"))\n",
    "    save_image(\n",
    "        tmp,\n",
    "        normalise=True,\n",
    "        base_dir=None,\n",
    "        out_dir=out_dir,\n",
    "        filename=filename_raw+'__labels.tif'\n",
    "    )\n",
    "\n",
    "    continue\n",
    "\n",
    "    # if E14\n",
    "    image_prox = image.data[:int(Lx/2),:]\n",
    "    image_prox = skimage.filters.gaussian(image_prox, sigma=0.5)\n",
    "    image_prox = skimage.morphology.white_tophat(image_prox, skimage.morphology.disk(15))\n",
    "    image_prox = skimage.exposure.equalize_adapthist(image_prox, kernel_size=15, clip_limit=0.01)\n",
    "\n",
    "    image_dist = image.data[int(Lx/2):,:]\n",
    "    image_dist = skimage.filters.gaussian(image_dist, sigma=0.5)\n",
    "    image_dist = skimage.morphology.white_tophat(image_dist, skimage.morphology.disk(10))\n",
    "    image_dist = skimage.exposure.equalize_adapthist(image_dist, kernel_size=10, clip_limit=0.01)\n",
    "\n",
    "    img = np.zeros_like(image.data)\n",
    "    img[:int(Lx/2),:] = image_prox\n",
    "    img[int(Lx/2):,:] = image_dist\n",
    "\n",
    "    # Else\n",
    "    #     img = image.data\n",
    "    #     img = skimage.filters.gaussian(img, sigma=0.5)\n",
    "    #     img = skimage.morphology.white_tophat(img, skimage.morphology.disk(10))\n",
    "    #     img = skimage.exposure.equalize_adapthist(img, kernel_size=10, clip_limit=0.01)\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=[20, 20])\n",
    "\n",
    "    axes[0].imshow(image.T, interpolation='none', cmap='gray')\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax.set_aspect(1)\n",
    "    ax.imshow(img.T, cmap='gray')\n",
    "\n",
    "\n",
    "    thresh = skimage.filters.threshold_otsu(img)\n",
    "\n",
    "    bw = np.where(img > thresh/1.3, 1, 0)\n",
    "    bw = skimage.morphology.binary_dilation(bw)\n",
    "\n",
    "    distance = scipy.ndimage.distance_transform_edt(bw)\n",
    "    \n",
    "    \n",
    "    # if E14\n",
    "    coords = skimage.feature.peak_local_max(distance[:int(Lx/4),:], labels=bw[:int(Lx/4),:], min_distance=16)\n",
    "    mask_prox = np.zeros(distance[:int(Lx/4),:].shape, dtype=bool)\n",
    "    mask_prox[tuple(coords.T)] = True\n",
    "\n",
    "    coords = skimage.feature.peak_local_max(distance[int(Lx/4):int(Lx*3/4),:], labels=bw[int(Lx/4):int(Lx*3/4),:], min_distance=12)\n",
    "    mask_mid = np.zeros(distance[int(Lx/4):int(Lx*3/4),:].shape, dtype=bool)\n",
    "    mask_mid[tuple(coords.T)] = True\n",
    "\n",
    "    coords = skimage.feature.peak_local_max(distance[int(Lx*3/4):,:], labels=bw[int(Lx*3/4):,:], min_distance=8)\n",
    "    mask_dist = np.zeros(distance[int(Lx*3/4):,:].shape, dtype=bool)\n",
    "    mask_dist[tuple(coords.T)] = True\n",
    "\n",
    "    mask = np.zeros_like(distance, dtype=bool)\n",
    "    mask[:int(Lx/4),:] = mask_prox\n",
    "    mask[int(Lx/4):int(Lx*3/4),:] = mask_mid\n",
    "    mask[int(Lx*3/4):,:] = mask_dist\n",
    "\n",
    "    # else\n",
    "    # coords = skimage.feature.peak_local_max(distance, labels=bw, min_distance=10)\n",
    "    # mask = np.zeros(distance.shape, dtype=bool)\n",
    "    # mask[tuple(coords.T)] = True\n",
    "\n",
    "\n",
    "    markers, _ = scipy.ndimage.label(mask)\n",
    "\n",
    "\n",
    "    __labels = xr.zeros_like(image, dtype=int)\n",
    "    __labels[:int(Lx/3),:] += skimage.segmentation.watershed(-distance[:int(Lx/3),:], markers[:int(Lx/3),:], mask=bw[:int(Lx/3),:])\n",
    "    __voronoi = xr.zeros_like(image, dtype=int) # + skimage.segmentation.watershed(-distance, markers, mask=image)\n",
    "\n",
    "    labels = xr.zeros_like(__labels) + __labels\n",
    "    voronoi = xr.zeros_like(__voronoi) + __voronoi\n",
    "    ids = np.unique(__labels)[1:]\n",
    "    # if np.unique(__voronoi)[1:].shape[0] != ids.shape[0]:\n",
    "    #     raise\n",
    "\n",
    "    # np.random.shuffle(ids)\n",
    "    # for i, rid in enumerate(ids):\n",
    "    #     labels = np.where(__labels==i+1, rid, labels)\n",
    "    #     voronoi = np.where(__voronoi==i+1, rid, voronoi)\n",
    "\n",
    "    labels = xr.zeros_like(image, dtype=int) + labels\n",
    "    voronoi = xr.zeros_like(image, dtype=int) + voronoi\n",
    "    markers = xr.zeros_like(image, dtype=bool) + markers > 0\n",
    "    distance = xr.zeros_like(image) + distance\n",
    "    labels.attrs = image.attrs\n",
    "    voronoi.attrs = image.attrs\n",
    "    markers.attrs = image.attrs\n",
    "    distance.attrs = image.attrs\n",
    "\n",
    "    Labels[filename] = labels\n",
    "    Coords[filename] = coords\n",
    "    Voronoi[filename] = voronoi\n",
    "\n",
    "    print(f'Found {np.unique(labels).shape[0]-1} cells in {filename}.')\n",
    "\n",
    "    tmp = xr.concat([image, markers, labels, labels%15, distance], dim='c').assign_coords(c=[0,1,2,3,4])\n",
    "    tmp.attrs = image.attrs\n",
    "\n",
    "    filename_raw = filename.split('/')[-1].split('.')[0]\n",
    "    out_dir = os.path.join(basepath, path)\n",
    "    for p in  filename.split('/')[:-1]:\n",
    "        out_dir = os.path.join(out_dir, p)\n",
    "    out_dir = os.path.join(out_dir, filename_raw)\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    save_image(\n",
    "        tmp,\n",
    "        normalise=True,\n",
    "        base_dir=None,\n",
    "        out_dir=out_dir,\n",
    "        filename=filename_raw+'__labels.tif'\n",
    "    )\n",
    "\n",
    "image=None\n",
    "del image\n",
    "img=None\n",
    "del img\n",
    "thresh=None\n",
    "del thresh\n",
    "bw=None\n",
    "del bw\n",
    "distance=None\n",
    "del distance\n",
    "coords=None\n",
    "del coords\n",
    "mask=None\n",
    "del mask\n",
    "markers=None\n",
    "del markers\n",
    "labels=None\n",
    "del labels\n",
    "__labels=None\n",
    "del __labels\n",
    "voronoi=None\n",
    "del voronoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.bincount(labels.data.flatten()).shape)\n",
    "print(np.unique(labels.data.flatten()).shape)\n",
    "# print(measure_cells(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError(\"Please apply manual corrections and create a '<filename>__labels__manual_corrections.tif' file before continuing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manuals = dict()\n",
    "for filename in Images.keys():\n",
    "    image = Images[filename].copy()\n",
    "    if filename in Originals.keys():\n",
    "        original = Originals[filename].copy()\n",
    "    else:\n",
    "        original = Images[filename].copy()\n",
    "\n",
    "    filename_raw = filename.split('/')[-1].split('.')[0]\n",
    "    out_dir = os.path.join(basepath, path)\n",
    "    for p in  filename.split('/')[:-1]:\n",
    "        out_dir = os.path.join(out_dir, p)\n",
    "    out_dir = os.path.join(out_dir, filename_raw)\n",
    "\n",
    "    try:\n",
    "        tmp = load_image(\n",
    "            base_dir = None,\n",
    "            in_dir=out_dir,\n",
    "            filename=f'{filename_raw}__labels__manual_corrections.tif',\n",
    "            dims=['c', 'y', 'x'],\n",
    "            normalise=True,\n",
    "            logger=log\n",
    "        ).squeeze()\n",
    "        mask = tmp.isel(c=1) > 0\n",
    "        # distance = scipy.ndimage.distance_transform_edt(mask)\n",
    "        tmp = None\n",
    "        del tmp\n",
    "    except RuntimeError as err:\n",
    "        print(f\"ERROR loading manual corrections for {filename}:\")\n",
    "        print(err)\n",
    "        continue\n",
    "    \n",
    "    # coords = skimage.feature.peak_local_max(distance, labels=mask, min_distance=3)\n",
    "    # seeds = np.zeros(image.shape, dtype=bool)\n",
    "    # seeds[tuple(coords.T)] = True\n",
    "\n",
    "    # markers, _ = scipy.ndimage.label(seeds)\n",
    "\n",
    "    # _labels = np.zeros_like(image, dtype=int) + skimage.segmentation.watershed(-distance, markers, mask=mask)\n",
    "\n",
    "    # labels = xr.zeros_like(image, dtype=int) + _labels\n",
    "    labels = xr.zeros_like(image, dtype=int) + scipy.ndimage.label(mask.data)[0]\n",
    "    voronoi = xr.zeros_like(image, dtype=int) # + _labels\n",
    "    # markers = (xr.zeros_like(image, dtype=int) + markers).where(labels > 0, 0)\n",
    "    # distance = xr.zeros_like(image, dtype=int) + distance\n",
    "    labels.attrs = original.attrs\n",
    "    # voronoi.attrs = original.attrs\n",
    "    # markers.attrs = original.attrs\n",
    "    # distance.attrs = original.attrs\n",
    "\n",
    "    objects = measure_cells(labels, exclude_distance=np.inf, minimum_area=1)\n",
    "\n",
    "    print(f'Found {np.unique(labels).shape[0]-1} cells in {filename}.')\n",
    "    cnt_exclude = objects['exclude'].sum()\n",
    "    print(f'Excluding {cnt_exclude} cells based on local 2 std area criterion.')\n",
    "\n",
    "    # for id in objects.loc[objects['exclude'], 'id']:\n",
    "    #     labels = labels.where(labels!=id, 0)\n",
    "\n",
    "    # Labels[filename] = labels\n",
    "    # Coords[filename] = coords\n",
    "    # Voronoi[filename] = voronoi\n",
    "\n",
    "    print(f'Identified {np.unique(labels).shape[0]-1} cells in {filename}.')\n",
    "\n",
    "    tmp = xr.concat([original, labels.where(labels==0, labels % 20 + 6)], dim='c', coords='minimal').assign_coords(c=[0,1])\n",
    "\n",
    "    print(f\"Saving result ...\")\n",
    "    objects.to_csv(os.path.join(out_dir, f\"{filename_raw}.csv\"))\n",
    "    save_image(\n",
    "        tmp,\n",
    "        normalise=True,\n",
    "        base_dir=None,\n",
    "        out_dir=out_dir,\n",
    "        filename=filename_raw+'__labels.tif'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError(\"Please finalise manual corrections and create a '<filename>__labels__final.tif' file before continuing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(objects['exclude'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate on identified cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voronoi_neighbors(voronoi, *, objects):\n",
    "    nbs = []\n",
    "    Lx, Ly = voronoi.shape\n",
    "    Lx -= 1\n",
    "    Ly -= 1\n",
    "    for i, cell in objects.iterrows():\n",
    "        id = cell['id']\n",
    "        x = cell['center_x_pixels']\n",
    "        y = cell['center_y_pixels']\n",
    "\n",
    "        voronoi_nbs = voronoi[max(0, x-50):min(Lx, x+50), max(0, y-50):min(Ly, y+50)].where(\n",
    "            # get all the pixels adjacent to voronoi cell\n",
    "            skimage.morphology.binary_dilation(voronoi.data[max(0, x-50):min(Lx, x+50), max(0, y-50):min(Ly, y+50)] == id, np.ones((3,3)))  ^ (voronoi.data[max(0, x-50):min(Lx, x+50), max(0, y-50):min(Ly, y+50)] == id), \n",
    "            0\n",
    "        )\n",
    "        \n",
    "        if voronoi_nbs.sum() == 0:\n",
    "            # print(f\"No voronoi nbs found for cell {cell['id']}\")\n",
    "            nbs.append('')\n",
    "            continue\n",
    "\n",
    "        _nbs = ''\n",
    "        cnt = 0\n",
    "        for n in np.unique(voronoi_nbs)[1:]:\n",
    "            cnt += 1\n",
    "            _nbs += str(n) + ','\n",
    "        if cnt >= 3:\n",
    "            nbs.append(_nbs[:-1])\n",
    "        else:\n",
    "            nbs.append('')\n",
    "\n",
    "    return np.asarray(nbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "def r_ellipse(theta, a, b, theta0):\n",
    "    return a * b / (  (b * np.cos(theta - theta0))**2\n",
    "                    + (a * np.sin(theta - theta0))**2)**0.5\n",
    "\n",
    "def p_atic_order_parameter(displ_x, displ_y, *, p, corrected=False):\n",
    "    def __rescale_dx_dy(displ_x, displ_y, *, ratio_WH, theta):\n",
    "        \"\"\"Rescale to circle for correction\"\"\"\n",
    "        dx_ = (displ_x * np.cos(-theta) - displ_y * np.sin(-theta)) / ratio_WH\n",
    "        dy_ =  displ_x * np.sin(-theta) + displ_y * np.cos(-theta)\n",
    "\n",
    "        dx = dx_ * np.cos(theta) - dy_ * np.sin(theta)\n",
    "        dy = dx_ * np.sin(theta) + dy_ * np.cos(theta)\n",
    "\n",
    "        return dx, dy\n",
    "    \n",
    "\n",
    "    if displ_x.size < 3:\n",
    "        if isinstance(p, numbers.Number):\n",
    "            return 0.\n",
    "        else:\n",
    "            return np.zeros_like(p)\n",
    "    \n",
    "    if not corrected:\n",
    "        angles = np.arctan2(displ_y, displ_x)\n",
    "    else:\n",
    "        p0 = 1.01, 0.99, 0.01\n",
    "        try: \n",
    "            popt, _ = curve_fit(r_ellipse,\n",
    "                                np.arctan2(displ_y, displ_x), (displ_x**2 + displ_y**2)**0.5,\n",
    "                                p0, sigma = (displ_x**2 + displ_y**2)**0.5)\n",
    "            A, B, Alpha = popt\n",
    "            dx, dy = __rescale_dx_dy(displ_x, displ_y, ratio_WH=A/B, theta=Alpha)\n",
    "            angles = np.arctan2(dy, dx)\n",
    "        except RuntimeError as err:\n",
    "            print(err)\n",
    "            angles = np.arctan2(displ_y, displ_x)\n",
    "\n",
    "    if isinstance(p, numbers.Number):\n",
    "        return np.abs((np.exp(p * 1j * angles)).sum()) / angles.shape[0]\n",
    "    else:\n",
    "        return np.asarray(\n",
    "            [\n",
    "                np.abs((np.exp(_p * 1j * angles)).sum()) / angles.shape[0]\n",
    "                for _p in p\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_atic_order(cell, *, objects, ps):\n",
    "    if type(cell['neighbors_voronoi']) is str:\n",
    "        if len(cell['neighbors_voronoi']) == 0:\n",
    "            nbs = []\n",
    "        else:\n",
    "            nbs = cell['neighbors_voronoi'].split(',')\n",
    "    else:\n",
    "        nbs = cell['neighbors_voronoi']\n",
    "    \n",
    "    nbs = np.asarray(nbs, dtype=int)\n",
    "    \n",
    "    nbs_x = np.asarray([objects.loc[n, 'center_x_pixels'] for n in nbs])\n",
    "    nbs_y = np.asarray([objects.loc[n, 'center_y_pixels'] for n in nbs])\n",
    "\n",
    "    displ_x = nbs_x - cell['center_x_pixels']\n",
    "    displ_y = nbs_y - cell['center_y_pixels']\n",
    "\n",
    "\n",
    "    return nbs, p_atic_order_parameter(displ_x, displ_y, p=ps, corrected=False), p_atic_order_parameter(displ_x, displ_y, p=ps, corrected=True)\n",
    "\n",
    "def apply_p_atic_order(objects, *, ps):\n",
    "    tmp_result = objects.apply(p_atic_order, axis=1, objects=objects, ps=ps)\n",
    "\n",
    "    result = pd.DataFrame()    \n",
    "    for i, p in enumerate(ps):\n",
    "        if i == 0:\n",
    "            result['next_HC_neighbors'] = tmp_result.apply(lambda r: np.asarray(r[0]).astype(int))\n",
    "            result['num_next_HC_neighbors'] = tmp_result.apply(lambda r: len(r[0]))\n",
    "\n",
    "        result[f'{p}-atic_order'] = tmp_result.apply(lambda r: r[1][i])\n",
    "        result[f'{p}-atic_order_corrected'] = tmp_result.apply(lambda r: r[2][i])\n",
    "        if p == 6:\n",
    "            result['hexatic_order'] = tmp_result.apply(lambda r: r[1][i])\n",
    "            result['hexatic_order_corrected'] = tmp_result.apply(lambda r: r[2][i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mask(radius):\n",
    "    x = np.linspace(-radius, radius, 2*radius+1)  # Adjust bounds to include the circle\n",
    "    y = np.linspace(-radius, radius, 2*radius+1)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Calculate the distance from the center (0, 0)\n",
    "    distance = np.sqrt(X**2 + Y**2)\n",
    "\n",
    "    # Create the mask: 1 inside the circle, 0 outside\n",
    "    return (distance <= radius).astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = dict()\n",
    "Voronoi = dict()\n",
    "Objects = dict()\n",
    "for filename in Images.keys():\n",
    "    print(filename)\n",
    "\n",
    "    image = Images[filename].copy()\n",
    "    if filename in Originals.keys():\n",
    "        original = Originals[filename].copy()\n",
    "    else:\n",
    "        original = Images[filename].copy()\n",
    "\n",
    "    filename_raw = filename.split('/')[-1].split('.')[0]\n",
    "    out_dir = os.path.join(basepath, path)\n",
    "    for p in  filename.split('/')[:-1]:\n",
    "        out_dir = os.path.join(out_dir, p)\n",
    "    out_dir = os.path.join(out_dir, filename_raw)\n",
    "\n",
    "    try:\n",
    "        tmp = load_image(\n",
    "            base_dir = None,\n",
    "            in_dir=out_dir,\n",
    "            filename=f'{filename_raw}__labels__final.tif',\n",
    "            dims=['c', 'y', 'x'],\n",
    "            normalise=True,\n",
    "            logger=log\n",
    "        ).squeeze()\n",
    "        mask = tmp.isel(c=1) > 0\n",
    "        tmp = None\n",
    "        del tmp\n",
    "    except RuntimeError as err:\n",
    "        print(f\"ERROR loading manual corrections for {filename}:\")\n",
    "        print(err)\n",
    "        continue\n",
    "\n",
    "    labels = xr.zeros_like(image, dtype=int) + scipy.ndimage.label(mask.data)[0]\n",
    "    labels.attrs = original.attrs\n",
    "\n",
    "    Labels[filename] = labels\n",
    "\n",
    "    objects = measure_cells(labels, exclude_distance=np.inf, minimum_area=1)\n",
    "    objects['exclude'] = False\n",
    "    print(f'Identified {np.unique(labels).shape[0]-1} cells in {filename}.')\n",
    "\n",
    "    # voronoi tesselation for hexatic order\n",
    "    coords = np.asarray(np.round([[xy[0], xy[1]] for xy in objects['center_pixels']]), dtype=int)\n",
    "    seeds = np.zeros(image.shape, dtype=bool)\n",
    "    seeds[tuple(coords.T)] = True\n",
    "    markers = labels.where(seeds, 0).data\n",
    "\n",
    "    distance = scipy.ndimage.distance_transform_edt(mask)\n",
    "    voronoi = xr.zeros_like(image, dtype=int) + skimage.segmentation.watershed(-distance, markers, mask=original)\n",
    "    voronoi.attrs = original.attrs\n",
    "    Voronoi[filename] = voronoi\n",
    "\n",
    "    objects['neighbors_voronoi'] = voronoi_neighbors(voronoi, objects=objects)\n",
    "    objects = pd.concat([objects, apply_p_atic_order(objects=objects, ps=range(3, 10))], axis=1)\n",
    "\n",
    "    print(f\"Saving result ...\")\n",
    "    objects.to_csv(os.path.join(out_dir, f\"{filename_raw}__final.csv\"))\n",
    "    Objects[filename] = objects\n",
    "\n",
    "    psi_6 = objects['hexatic_order'].mean()\n",
    "    print(f'Mean hexatic order: {psi_6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objects = pd.DataFrame()\n",
    "# Objects['filename'] = ''\n",
    "\n",
    "# def hexatic_order(cell, *, objects):\n",
    "#     nbs = cell['neighbors_voronoi']\n",
    "\n",
    "#     if len([n for n in nbs if not objects.loc[objects['id']==n].empty]) < 3:\n",
    "#         return 0.\n",
    "\n",
    "#     nbs_x = np.asarray([objects.loc[n, 'barycenter_x_pixels'] for n in nbs if not objects.loc[objects['id']==n].empty])\n",
    "#     nbs_y = np.asarray([objects.loc[n, 'barycenter_y_pixels'] for n in nbs if not objects.loc[objects['id']==n].empty])\n",
    "\n",
    "#     return np.abs(np.exp(6j * np.arctan2(nbs_y - cell['barycenter_y_pixels'], nbs_x - cell['barycenter_x_pixels'])).sum()) / nbs_x.size\n",
    "\n",
    "# # TODO replace with the respective function in utils.py\n",
    "# def elongation(coordinates, *, barycenter):\n",
    "#     phi = np.arctan2(coordinates[:,1]-barycenter[1],\n",
    "#                      coordinates[:,0]-barycenter[0])\n",
    "    \n",
    "#     q1 = (np.cos(2*phi)).sum() / coordinates.shape[0]\n",
    "#     q2 = (np.sin(2*phi)).sum() / coordinates.shape[0]\n",
    "\n",
    "#     q = (q1**2 + q2**2)**0.5\n",
    "#     orientation = np.arctan2(q2, q1) / 2\n",
    "    \n",
    "#     return q, orientation, q1, q2\n",
    "\n",
    "\n",
    "# # TODO replace with the respective function in utils.py\n",
    "# def HCA_polarity(coordinates, *, intensity, barycenter):\n",
    "#     phi = np.arctan2(coordinates[:,1]-barycenter[1],\n",
    "#                      coordinates[:,0]-barycenter[0])\n",
    "    \n",
    "#     px = (intensity * np.cos(phi)).sum() / intensity.sum()\n",
    "#     py = (intensity * np.sin(phi)).sum() / intensity.sum()\n",
    "\n",
    "#     p = (px**2 + py**2)**0.5\n",
    "#     orientation = np.arctan2(py, px)\n",
    "    \n",
    "#     return p, orientation, px, py\n",
    "\n",
    "# # def local_tangent_to_axis(coordinates, *, )\n",
    "\n",
    "# # analyse the objects\n",
    "# for filename in filenames:\n",
    "#     print(f'processing {filename} ...')\n",
    "#     _labels = Labels[filename]\n",
    "#     if 'z' in Images[filename].dims:\n",
    "#         image = Images[filename].max(dim='z')\n",
    "#     else:\n",
    "#         image = Images[filename]\n",
    "#     image.attrs = Images[filename].attrs\n",
    "#     _voronoi = Voronoi[filename]\n",
    "#     objects = pd.DataFrame()\n",
    "#     objects['filename'] = ''\n",
    "#     objects['id'] = 0\n",
    "\n",
    "#     size = 200\n",
    "#     overlap = 50\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     report_time = start_time\n",
    "#     for x in range(0, _labels.shape[0], size):\n",
    "#         if time.time() - report_time > 10:\n",
    "#             report_time = time.time()\n",
    "#             print(f'  progress: {x/_labels.shape[0]} in {time.time() - start_time}s')\n",
    "#         for y in range(0, _labels.shape[1], size):\n",
    "#             labels = _labels.isel(\n",
    "#                 x=slice(np.max([x-overlap, 0]), x+size+overlap),\n",
    "#                 y=slice(np.max([y-overlap, 0]), y+size+overlap),\n",
    "#             )\n",
    "#             voronoi = _voronoi.isel(\n",
    "#                 x=slice(np.max([x-overlap, 0]), x+size+overlap),\n",
    "#                 y=slice(np.max([y-overlap, 0]), y+size+overlap),\n",
    "#             )\n",
    "\n",
    "#             for id in np.unique(labels):\n",
    "#                 if id == 0 or not objects.loc[objects['id']==id].empty:\n",
    "#                     continue\n",
    "\n",
    "#                 cell = labels.where(labels == id)\n",
    "\n",
    "#                 # exclude cells on boundary of image\n",
    "#                 if (\n",
    "#                     np.count_nonzero(~np.isnan(cell[0, :])) + \n",
    "#                     np.count_nonzero(~np.isnan(cell[1, :])) + \n",
    "#                     np.count_nonzero(~np.isnan(cell[-1, :])) +\n",
    "#                     np.count_nonzero(~np.isnan(cell[-2, :])) +\n",
    "#                     np.count_nonzero(~np.isnan(cell[:, 0])) + \n",
    "#                     np.count_nonzero(~np.isnan(cell[:, 1])) + \n",
    "#                     np.count_nonzero(~np.isnan(cell[:, -1])) +\n",
    "#                     np.count_nonzero(~np.isnan(cell[:, -2]))\n",
    "#                 ):\n",
    "#                     continue\n",
    "\n",
    "#                 objects.loc[id, 'id'] = id\n",
    "\n",
    "#                 # the coordinate axes\n",
    "#                 coordinates = np.argwhere((labels == id).data)\n",
    "#                 coordinates = np.asarray(coordinates, dtype=float)\n",
    "#                 coordinates = coordinates + np.array([np.max([x-overlap, 0]), \n",
    "#                                                       np.max([y-overlap, 0])])\n",
    "                              \n",
    "                \n",
    "#                 # calculate in pixel dimensions\n",
    "#                 barycenter = coordinates.mean(0)\n",
    "#                 max = coordinates.max(0)\n",
    "#                 min = coordinates.min(0)\n",
    "\n",
    "#                 mask = np.where(labels == id, 1, 0)\n",
    "#                 area = mask.sum()\n",
    "\n",
    "#                 objects.loc[id, 'area_pixels'] = area\n",
    "#                 for i, axis in enumerate(['x', 'y']):\n",
    "#                     objects.loc[id, 'barycenter_{}_pixels'.format(axis)] = barycenter[i]\n",
    "#                 for i, axis in enumerate(['x', 'y']):\n",
    "#                     objects.loc[id, 'min_{}_pixels'.format(axis)] = min[i]\n",
    "#                     objects.loc[id, 'max_{}_pixels'.format(axis)] = max[i]\n",
    "\n",
    "#                 Q = elongation(coordinates, barycenter=barycenter)\n",
    "#                 objects.loc[id, 'elongation'] = Q[0]\n",
    "#                 objects.loc[id, 'elongation_orientation'] = Q[1]\n",
    "#                 objects.loc[id, 'elongation_q1'] = Q[2]\n",
    "#                 objects.loc[id, 'elongation_q2'] = Q[3]\n",
    "\n",
    "#                 # A list of intensities sorted like coordinates\n",
    "#                 intensity = image.isel(\n",
    "#                         x=slice(np.max([x-overlap, 0]), x+size+overlap),\n",
    "#                         y=slice(np.max([y-overlap, 0]), y+size+overlap),\n",
    "#                     ).data[labels==id]  \n",
    "#                 HCA_p = HCA_polarity(coordinates, intensity=intensity, barycenter=barycenter)\n",
    "\n",
    "#                 objects.loc[id, 'HCA_polarity'] = HCA_p[0]\n",
    "#                 objects.loc[id, 'HCA_polarity_orientation'] = HCA_p[1]\n",
    "#                 objects.loc[id, 'HCA_polarity_px'] = HCA_p[2]\n",
    "#                 objects.loc[id, 'HCA_polarity_py'] = HCA_p[3]\n",
    "\n",
    "#                 voronoi_nbs = voronoi.where(\n",
    "#                     # get all the pixels adjacent to voronoi cell\n",
    "#                     skimage.morphology.binary_dilation(voronoi.data == id),\n",
    "#                     0\n",
    "#                 )\n",
    "\n",
    "#                 _nbs = ''\n",
    "#                 cnt = 0\n",
    "#                 for n in np.unique(voronoi_nbs):\n",
    "#                     if n != 0 and n != id:\n",
    "#                         cnt += 1\n",
    "#                         _nbs += str(n) + ','\n",
    "#                 if cnt >= 3:\n",
    "#                     objects.loc[id, 'neighbors_voronoi'] = _nbs[:-1]\n",
    "#                 else:\n",
    "#                     objects.loc[id, 'neighbors_voronoi'] = '0,0,0'\n",
    "#     print(f'Measured HCs in {time.time() - start_time}s. Postprocessing ... ')\n",
    "\n",
    "#     # use image resolution\n",
    "#     res_x = image.attrs.get('resolution_x', np.nan)\n",
    "#     res_y = image.attrs.get('resolution_y', np.nan)\n",
    "#     res_z = image.attrs.get('resolution_z', np.nan)\n",
    "\n",
    "#     aspect = res_x / res_y\n",
    "#     print(f\"{image.attrs['resolution_scale']}: {res_x} x {res_y} ({aspect})\")\n",
    "\n",
    "#     objects['area'] = objects['area_pixels'] / res_x / res_y\n",
    "\n",
    "#     objects['barycenter_x'] = objects['barycenter_x_pixels'] / res_x\n",
    "#     objects['barycenter_y'] = objects['barycenter_y_pixels'] / res_y\n",
    "\n",
    "#     objects['min_x'] = objects['min_x_pixels'] / res_x\n",
    "#     objects['max_x'] = objects['max_x_pixels'] / res_x\n",
    "#     objects['min_y'] = objects['min_y_pixels'] / res_y\n",
    "#     objects['max_y'] = objects['max_y_pixels'] / res_y\n",
    "\n",
    "#     objects['neighbors_voronoi'] = objects['neighbors_voronoi'].apply(lambda s: np.asarray(s.split(','), dtype=int))\n",
    "#     objects['num_neighbors_voronoi'] = objects['neighbors_voronoi'].apply(lambda nbs: nbs.size)\n",
    "\n",
    "#     print(\"  Calculating hexatic order ...\")\n",
    "#     objects['hexatic_order'] = objects[['neighbors_voronoi', 'barycenter_x_pixels', 'barycenter_y_pixels']].apply(hexatic_order, axis=1, objects=objects)\n",
    "#     print(\"  Done.\")\n",
    "\n",
    "#     objects['filename'] = filename\n",
    "\n",
    "#     # Excluding cells outside 2 sigma from local average area\n",
    "#     print(\"  Excluding cells outside 2 sigma from local average area.\")\n",
    "#     distance = scipy.spatial.distance_matrix(\n",
    "#         objects[['barycenter_x_pixels', 'barycenter_y_pixels']],\n",
    "#         objects[['barycenter_x_pixels', 'barycenter_y_pixels']]\n",
    "#     )\n",
    "#     distance_mask = distance < 500\n",
    "\n",
    "#     i = 0\n",
    "#     for index, row in objects.iterrows():\n",
    "#         objects.loc[index, 'local_area_pixel'] = objects.loc[distance_mask[i], 'area_pixels'].mean()\n",
    "#         objects.loc[index, 'local_area_pixel__std'] = objects.loc[distance_mask[i], 'area_pixels'].std()\n",
    "#         i += 1\n",
    "\n",
    "#     objects['exclude'] = (\n",
    "#           (objects['area_pixels'] < objects['local_area_pixel'] - 2 * objects['local_area_pixel__std'])\n",
    "#         | (objects['area_pixels'] > objects['local_area_pixel'] + 2 * objects['local_area_pixel__std'])\n",
    "#     )\n",
    "    \n",
    "#     filename_raw = filename.split('/')[-1].split('.')[0]\n",
    "#     out_dir = os.path.join(basepath, path)\n",
    "#     for p in  filename.split('/')[:-1]:\n",
    "#         out_dir = os.path.join(out_dir, p)\n",
    "#     out_dir = os.path.join(out_dir, filename_raw)\n",
    "\n",
    "#     objects.to_csv(os.path.join(out_dir, f\"{filename_raw}.csv\"))\n",
    "\n",
    "#     Objects = pd.concat([Objects, objects])\n",
    "#     print(f'Finished file {filename} in {time.time() - start_time}s.')\n",
    "\n",
    "# print(Objects[['filename', 'area', 'num_neighbors_voronoi', 'hexatic_order']].groupby(by='filename').mean())\n",
    "\n",
    "# _labels=None\n",
    "# del _labels\n",
    "# image=None\n",
    "# del image\n",
    "# _voronoi=None\n",
    "# del _voronoi\n",
    "# objects=None\n",
    "# del objects\n",
    "# labels=None\n",
    "# del labels\n",
    "# voronoi=None\n",
    "# del voronoi\n",
    "# cell=None\n",
    "# del cell\n",
    "# coordinates=None\n",
    "# del coordinates\n",
    "# intensity=None\n",
    "# del intensity\n",
    "# mask=None\n",
    "# del mask\n",
    "# voronoi_nbs=None\n",
    "# del voronoi_nbs\n",
    "# distance=None\n",
    "# del distance\n",
    "# distance_mask=None\n",
    "# del distance_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure curvature in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PD_position(data):\n",
    "    result = data['curvature_tangent_orientation']\n",
    "    result -= result.min()\n",
    "    result /= result.max()\n",
    "    return result\n",
    "\n",
    "def PD_binned_position(tangent, bins=[0., 0.125, 0.375, 0.625, 0.875, 1.0], digits=3):\n",
    "    # arguments:\n",
    "    #   - bins: the right edges of the bins\n",
    "    binned = np.zeros_like(tangent)\n",
    "    bins[-1] += 1.e-8\n",
    "    for i, bin in enumerate(bins[:-1]):\n",
    "        binned += (tangent >= bin) * (tangent < bins[i+1]) * (bins[i+1] + bins[i]) / 2.\n",
    "    binned = np.round(binned * 10**digits) / 10**digits\n",
    "    return binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_R(xc, yc):\n",
    "    \"\"\" calculate the distance of each data points from the center (xc, yc) \"\"\"\n",
    "    return np.sqrt((x-xc)**2 + (y-yc)**2)\n",
    "\n",
    "def f_2b(c):\n",
    "    \"\"\" calculate the algebraic distance between the 2D points and the mean circle centered at c=(xc, yc) \"\"\"\n",
    "    Ri = calc_R(*c)\n",
    "    return Ri - Ri.mean()\n",
    "\n",
    "def Df_2b(c):\n",
    "    \"\"\" Jacobian of f_2b\n",
    "    The axis corresponding to derivatives must be coherent with the col_deriv option of leastsq\"\"\"\n",
    "    xc, yc     = c\n",
    "    df2b_dc    = np.empty((len(c), x.size))\n",
    "\n",
    "    Ri = calc_R(xc, yc)\n",
    "    df2b_dc[0] = (xc - x)/Ri                   # dR/dxc\n",
    "    df2b_dc[1] = (yc - y)/Ri                   # dR/dyc\n",
    "    df2b_dc    = df2b_dc - df2b_dc.mean(axis=1)[:, np.newaxis]\n",
    "\n",
    "    return df2b_dc\n",
    "\n",
    "figsize=8\n",
    "for filename in filenames:\n",
    "# for filename in ['E14_2025/3_cleaning/E14_1.tif']:\n",
    "    print(filename)\n",
    "\n",
    "    filename_raw = filename.split('/')[-1].split('.')[0]\n",
    "    out_dir = os.path.join(basepath, path)\n",
    "    for p in  filename.split('/')[:-1]:\n",
    "        out_dir = os.path.join(out_dir, p)\n",
    "    out_dir = os.path.join(out_dir, filename_raw)\n",
    "\n",
    "    if os.path.isfile(os.path.join(out_dir, f\"{filename_raw}__final.csv\")):\n",
    "        objects = pd.read_csv(os.path.join(out_dir, f\"{filename_raw}__final.csv\"))\n",
    "        if 'Unnamed: 0' in objects.columns:\n",
    "            objects = objects.drop(columns='Unnamed: 0')\n",
    "        objects.set_index('id')\n",
    "    else:\n",
    "        raise\n",
    "        objects = Objects[filename]\n",
    "\n",
    "    labels = Labels[filename]    \n",
    "        \n",
    "    image = Images[filename].copy()\n",
    "    if filename in Originals.keys():\n",
    "        original = Originals[filename].copy()\n",
    "    else:\n",
    "        original = Images[filename].copy()\n",
    "    img = original.copy()\n",
    "\n",
    "    x = np.asarray(objects['center_x_um'])\n",
    "    y = np.asarray(objects['center_y_um'])\n",
    "    center_estimate = x.mean(), y.mean()\n",
    "    center_2b, ier = scipy.optimize.leastsq(f_2b, center_estimate, Dfun=Df_2b, col_deriv=True)\n",
    "\n",
    "    xc_2b, yc_2b = center_2b\n",
    "    Ri_2b        = calc_R(*center_2b)\n",
    "    R_2b         = Ri_2b.mean()\n",
    "    residu_2b    = sum((Ri_2b - R_2b)**2)\n",
    "\n",
    "    print(f'Radius: {R_2b} $\\mu m$')\n",
    "    print(f'curvature: {1/R_2b} $\\mu m^-1$')\n",
    "    print(f'curvature: {1/(R_2b/2.8)} $A^-0.5$')\n",
    "\n",
    "    tissue = pd.Series()\n",
    "\n",
    "    tissue['filename'] = filename\n",
    "    tissue['stage'] = filename.split('/')[-1].split('_')[0]\n",
    "    tissue['curvature_center_x_um'] = xc_2b\n",
    "    tissue['curvature_center_y_um'] = yc_2b\n",
    "    tissue['curvature_radius_um'] = R_2b\n",
    "\n",
    "\n",
    "    x = np.asarray(objects['center_x_pixels'])\n",
    "    y = np.asarray(objects['center_y_pixels'])\n",
    "    center_estimate = x.mean(), y.mean()\n",
    "    center_2b, ier = scipy.optimize.leastsq(f_2b, center_estimate, Dfun=Df_2b, col_deriv=True)\n",
    "\n",
    "    xc_2b, yc_2b = center_2b\n",
    "    Ri_2b        = calc_R(*center_2b)\n",
    "    R_2b         = Ri_2b.mean()\n",
    "    residu_2b    = sum((Ri_2b - R_2b)**2)\n",
    "\n",
    "    tissue['curvature_center_x_pixels'] = xc_2b\n",
    "    tissue['curvature_center_y_pixels'] = yc_2b\n",
    "    tissue['curvature_radius_pixels'] = R_2b\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "\n",
    "    ax.set_aspect(1)\n",
    "    if img is not None:\n",
    "        ax.imshow(img.T, cmap='gray')\n",
    "    else:\n",
    "        ax.scatter(x, y, s=1., linewidth=0.)\n",
    "\n",
    "    ax.plot(\n",
    "        R_2b * np.cos(np.linspace(0, 2*math.pi, 101)) + xc_2b, \n",
    "        R_2b * np.sin(np.linspace(0, 2*math.pi, 101)) + yc_2b,\n",
    "        label=\"curvature: %.2e $\\mu m^{-1}$ / %.2e $A^{-0.5}$\"%((1/tissue['curvature_radius_um']), 1/(tissue['curvature_radius_um']/objects['area_um2'].mean()**0.5))\n",
    "    )\n",
    "    ax.legend()\n",
    "    if img is not None:\n",
    "        ax.set_xlim(0, img.shape[0])\n",
    "        ax.set_ylim(img.shape[1], 0)\n",
    "    else:\n",
    "        ax.set_xlim(x.min(), x.max())\n",
    "        ax.set_ylim(y.max(), y.min())\n",
    "\n",
    "    if img is not None:\n",
    "        if not os.path.isdir(os.path.join(out_dir, \"plots\")):\n",
    "            os.makedirs(os.path.join(out_dir, \"plots\"))\n",
    "        fig.savefig(os.path.join(out_dir, \"plots\", f\"{filename_raw}__curvature.svg\"),format='svg')\n",
    "\n",
    "    objects['curvature_tangent_orientation'] = np.arctan2(objects['center_y_um'] - tissue['curvature_center_y_um'], objects['center_x_um'] - tissue['curvature_center_x_um']) + math.pi/2\n",
    "    objects['position_PD'] = PD_position(objects)\n",
    "    objects['position_PD__binned'] = objects['position_PD'].apply(PD_binned_position, bins=[0., 0.125, 0.375, 0.625, 0.875, 1.0])\n",
    "    objects['position_PD__binned_20'] = objects['position_PD'].apply(PD_binned_position, bins=[0., 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    objects['position_PD__binned_12.5'] = objects['position_PD'].apply(PD_binned_position, bins=[0., 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1.0])\n",
    "\n",
    "    objects.to_csv(os.path.join(out_dir, f\"{filename_raw}__final.csv\"))\n",
    "    tissue.to_csv(os.path.join(out_dir, f\"{filename_raw}__tissue_properties.csv\"))\n",
    "\n",
    "    Objects[filename] = objects\n",
    "\n",
    "\n",
    "\n",
    "objects=None\n",
    "del objects\n",
    "img=None\n",
    "del img\n",
    "x=None\n",
    "del x\n",
    "y=None\n",
    "del y\n",
    "\n",
    "Ri_2b = None\n",
    "del Ri_2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Cell properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Objects.keys())\n",
    "print(Labels.keys())\n",
    "print(Voronoi.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.iinfo(np.short).max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_save_tif(image, *, normalise):\n",
    "    image = image.copy()\n",
    "    if normalise:\n",
    "        image -= image.min()\n",
    "        image /= image.max()\n",
    "        image *= np.iinfo(np.short).max\n",
    "        image = image.astype(dtype='uint16')\n",
    "        __image = None\n",
    "        del __image\n",
    "    else:\n",
    "        if (image.max() <= 1.):\n",
    "            raise RuntimeError(\"Cannot convert image with values <= 1 to uint16\")\n",
    "        image = image.astype(dtype='uint16')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "# for filename in ['E14_2025/3_cleaning/E14_1.tif']:\n",
    "    print(filename)\n",
    "\n",
    "    filename_raw = filename.split('/')[-1].split('.')[0]\n",
    "    out_dir = os.path.join(basepath, path)\n",
    "    for p in  filename.split('/')[:-1]:\n",
    "        out_dir = os.path.join(out_dir, p)\n",
    "    out_dir = os.path.join(out_dir, filename_raw)\n",
    "\n",
    "    if filename in Objects.keys():\n",
    "        objects = Objects[filename]\n",
    "        \n",
    "    elif os.path.isfile(os.path.join(out_dir, f\"{filename_raw}__final.csv\")):\n",
    "        objects = pd.read_csv(os.path.join(out_dir, f\"{filename_raw}__final.csv\"))\n",
    "        if 'Unnamed: 0' in objects.columns:\n",
    "            objects = objects.drop(columns='Unnamed: 0')\n",
    "        objects['center_pixels'] = objects['center_pixels'].apply(lambda s: np.asarray(s[1:-1].split(', '), dtype=float))\n",
    "    else:\n",
    "        raise\n",
    "    \n",
    "    labels = Labels[filename]    \n",
    "    voronoi = Voronoi[filename]\n",
    "\n",
    "    image = Images[filename].copy()\n",
    "    if filename in Originals.keys():\n",
    "        original = Originals[filename].copy()\n",
    "    else:\n",
    "        original = Images[filename].copy()\n",
    "\n",
    "    res_x = original.attrs['resolution_x']\n",
    "    res_y = original.attrs['resolution_y']\n",
    "    aspect = res_x / res_y\n",
    "    extent=[0, original.shape[0]/res_x, 0, original.shape[1]/res_y]\n",
    "    print(f\"{original.attrs['resolution_scale']}: {res_x} x {res_y} ({aspect})\")\n",
    "    if not np.isfinite(aspect):\n",
    "        raise RuntimeError(f\"No resolution available for image {filename}!\")\n",
    "    \n",
    "    area_map = xr.zeros_like(labels, dtype=float)\n",
    "    hexatic_map = xr.zeros_like(labels, dtype=float)\n",
    "    hexatic_map_c = xr.zeros_like(labels, dtype=float)\n",
    "    neighbour_map = xr.zeros_like(labels, dtype=float)\n",
    "    density_map = xr.zeros_like(labels, dtype=float)\n",
    "\n",
    "    # create a mask of the tissue\n",
    "    coords = np.asarray(np.round([[xy[0], xy[1]] for xy in objects['center_pixels']]), dtype=int)\n",
    "    seeds = np.zeros(image.shape, dtype=bool)\n",
    "    seeds[tuple(coords.T)] = True\n",
    "    tissue_map = xr.zeros_like(labels, dtype=float) + scipy.ndimage.binary_dilation(seeds, circular_mask(50))\n",
    "\n",
    "    Lx, Ly = original.shape\n",
    "    for id, cell in objects.iterrows():\n",
    "        if id % 500 == 0:\n",
    "            print(f\"Progress  : {id / objects['id'].max()} ...\")\n",
    "        x = cell['center_x_pixels']\n",
    "        y = cell['center_y_pixels']\n",
    "        x0, x1 = max(0, x - 50), min(Lx, x + 50 + 1)\n",
    "        y0, y1 = max(0, y - 50), min(Ly, y + 50 + 1)\n",
    "        area_map[x0:x1, y0:y1] = area_map[x0:x1, y0:y1].where(\n",
    "            labels[x0:x1, y0:y1] != id, cell['area_pixels'])\n",
    "        hexatic_map[x0:x1, y0:y1] = hexatic_map[x0:x1, y0:y1].where(\n",
    "            labels[x0:x1, y0:y1] != id, cell['hexatic_order'])\n",
    "        hexatic_map_c[x0:x1, y0:y1] = hexatic_map_c[x0:x1, y0:y1].where(\n",
    "            labels[x0:x1, y0:y1] != id, cell['hexatic_order_corrected'])\n",
    "        # neighbour_map[x0:x1, y0:y1] = neighbour_map[x0:x1, y0:y1].where(\n",
    "        #     labels[x0:x1, y0:y1] != id, cell['num_next_HC_neighbors']) \n",
    "        neighbour_map[x0:x1, y0:y1] = neighbour_map[x0:x1, y0:y1].where(\n",
    "            labels[x0:x1, y0:y1] != id, cell['position_PD__binned_12.5'])\n",
    "        # if id > 500:\n",
    "        #     break\n",
    "\n",
    "\n",
    "        dist = 50\n",
    "        cnt_labels = np.unique(labels[max(0, x - dist):min(Lx, x + dist + 1), max(0, y - dist):min(Ly, y + dist + 1)]).size - 1\n",
    "        cnt_pixels = tissue_map[max(0, x - dist):min(Lx, x + dist + 1), max(0, y - dist):min(Ly, y + dist + 1)].sum()\n",
    "        rho = cnt_labels / cnt_pixels / res_x / res_y\n",
    "        objects.loc[id, 'HC_density__50'] = rho\n",
    "\n",
    "        dist = 100\n",
    "        cnt_labels = np.unique(labels[max(0, x - dist):min(Lx, x + dist + 1), max(0, y - dist):min(Ly, y + dist + 1)]).size - 1\n",
    "        cnt_pixels = tissue_map[max(0, x - dist):min(Lx, x + dist + 1), max(0, y - dist):min(Ly, y + dist + 1)].sum()\n",
    "        rho = cnt_labels / cnt_pixels / res_x / res_y\n",
    "        objects.loc[id, 'HC_density__100'] = rho\n",
    "\n",
    "        density_map[x0:x1, y0:y1] = density_map[x0:x1, y0:y1].where(\n",
    "            labels[x0:x1, y0:y1] != id, rho)\n",
    "        \n",
    "        dist = 200\n",
    "        cnt_labels = np.unique(labels[max(0, x - dist):min(Lx, x + dist + 1), max(0, y - dist):min(Ly, y + dist + 1)]).size - 1\n",
    "        cnt_pixels = tissue_map[max(0, x - dist):min(Lx, x + dist + 1), max(0, y - dist):min(Ly, y + dist + 1)].sum()\n",
    "        rho = cnt_labels / cnt_pixels / res_x / res_y\n",
    "        objects.loc[id, 'HC_density__200'] = rho\n",
    "\n",
    "        dist = 500\n",
    "        cnt_labels = np.unique(labels[max(0, x - dist):min(Lx, x + dist + 1), max(0, y - dist):min(Ly, y + dist + 1)]).size - 1\n",
    "        cnt_pixels = tissue_map[max(0, x - dist):min(Lx, x + dist + 1), max(0, y - dist):min(Ly, y + dist + 1)].sum()\n",
    "        rho = cnt_labels / cnt_pixels / res_x / res_y\n",
    "        objects.loc[id, 'HC_density__500'] = rho\n",
    "\n",
    "    results = [\n",
    "        prepare_save_tif(original, normalise=True),\n",
    "        prepare_save_tif(area_map, normalise=False),\n",
    "        prepare_save_tif(hexatic_map * np.iinfo(np.short).max, normalise=False),\n",
    "        prepare_save_tif(hexatic_map_c * np.iinfo(np.short).max, normalise=False),\n",
    "        prepare_save_tif(neighbour_map, normalise=True),\n",
    "        prepare_save_tif(voronoi.where(voronoi==0, voronoi%20+1) / 21 * np.iinfo(np.short).max, normalise=False),\n",
    "        prepare_save_tif(tissue_map * np.iinfo(np.short).max, normalise=False),\n",
    "        prepare_save_tif(density_map, normalise=True),\n",
    "    ]\n",
    "    save_image(\n",
    "        xr.concat(results, dim='c', coords='minimal').assign_coords(c=range(len(results))),\n",
    "        normalise=False,\n",
    "        base_dir=None,\n",
    "        out_dir=out_dir,\n",
    "        filename=filename_raw+'__results.tif'\n",
    "    )\n",
    "\n",
    "    objects.to_csv(os.path.join(out_dir, f\"{filename_raw}__final.csv\"))\n",
    "\n",
    "    \n",
    "\n",
    "area_map = None\n",
    "del area_map\n",
    "hexatic_map = None\n",
    "del hexatic_map\n",
    "hexatic_map_c = None\n",
    "del hexatic_map_c\n",
    "neighbour_map = None\n",
    "del neighbour_map\n",
    "tissue_map = None\n",
    "del tissue_map\n",
    "results = None\n",
    "del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(objects.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError(\"Please proceed with analyse_restore_whole_BP.ipynb script to merge across files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Objects['Stage'] = Objects['filename'].apply(lambda name: name.split('/')[0])\n",
    "Objects['Stage'] = pd.Categorical(Objects['Stage'], [\"E8\", \"E10\", \"E12\"])\n",
    "\n",
    "Objects.to_csv(os.path.join(basepath, path, f\"summary.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Objects[['filename', 'curvature_tangent_orientation']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Objects['barycenter_x'].mean())\n",
    "print(Objects['curvature_center_x'].mean())\n",
    "print(Objects['barycenter_y'].mean())\n",
    "print(Objects['curvature_center_y'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval cell properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HC_number = Objects.groupby(by=['filename'])['area'].count().reset_index()\n",
    "HC_number = HC_number.rename(columns={'area': 'HC number'})\n",
    "HC_number['Stage'] = HC_number['filename'].apply(lambda name: name.split('/')[0])\n",
    "HC_number['Stage'] = pd.Categorical(HC_number['Stage'], [\"E8\", \"E10\", \"E12\"])\n",
    "\n",
    "HC_number = HC_number.loc[HC_number['HC number'] > 0]\n",
    "\n",
    "HC_number = HC_number.sort_values(by='Stage')\n",
    "print(HC_number)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=[1.5, 1.5])\n",
    "sns.swarmplot(data=HC_number, x='Stage', y='HC number', color='red')\n",
    "\n",
    "ax.set_ylim([0, 15000])\n",
    "ax.set_yticks([0, 5000, 10000, 15000])\n",
    "\n",
    "ax.set_xlim([-0.5, 3.5])\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels(['E8', 'E10', 'E12', 'E14'])\n",
    "\n",
    "plt.savefig(f\"{os.path.join(basepath, path)}/HC_number.svg\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=[1.5, 1.5])\n",
    "\n",
    "HC_number = Objects.groupby(by=['filename', 'position_PD__binned_20'])['area'].count().reset_index()\n",
    "HC_number = HC_number.rename(columns={'area': 'HC number'})\n",
    "HC_number['Stage'] = HC_number['filename'].apply(lambda name: name.split('/')[0])\n",
    "HC_number['Stage'] = pd.Categorical(HC_number['Stage'], [\"E8\", \"E10\", \"E12\"])\n",
    "\n",
    "HC_number = HC_number.loc[HC_number['HC number'] > 0]\n",
    "\n",
    "HC_number = HC_number.sort_values(by='Stage')\n",
    "print(HC_number)\n",
    "\n",
    "sns.swarmplot(data=HC_number, x='Stage', y='HC number', hue='position_PD__binned_20', palette='autumn', alpha=0.7)\n",
    "\n",
    "ax.set_xlim([-0.5, 3.5])\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels(['E8', 'E10', 'E12', 'E14'])\n",
    "\n",
    "ax.set_ylim([0, 3500])\n",
    "ax.set_yticks([0, 1000, 2000, 3000])\n",
    "\n",
    "plt.savefig(f\"{os.path.join(basepath, path)}/HC_number__binned.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=[3.5, 3.5])\n",
    "\n",
    "HC_number = Objects.groupby(by=['filename', 'position_PD__binned_20'])['area'].count().reset_index()\n",
    "HC_number = HC_number.rename(columns={'area': 'HC number'})\n",
    "HC_number['Stage'] = HC_number['filename'].apply(lambda name: name.split('/')[0])\n",
    "HC_number['Stage'] = pd.Categorical(HC_number['Stage'], [\"E8\", \"E10\", \"E12\"])\n",
    "\n",
    "HC_number = HC_number.loc[HC_number['HC number'] > 0]\n",
    "\n",
    "HC_number = HC_number.sort_values(by='Stage')\n",
    "print(HC_number)\n",
    "\n",
    "sns.pointplot(data=HC_number, x='Stage', y='HC number', hue='position_PD__binned_20', palette='autumn')\n",
    "\n",
    "ax.set_xlim([-0.5, 3.5])\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels(['E8', 'E10', 'E12', 'E14'])\n",
    "\n",
    "ax.set_ylim([0, 3500])\n",
    "ax.set_yticks([0, 1000, 2000, 3000])\n",
    "\n",
    "plt.savefig(f\"{os.path.join(basepath, path)}/HC_number__binned_mean.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    print(Objects.loc[Objects['filename']==filename])\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[15, 6])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect(1)\n",
    "    sns.scatterplot(\n",
    "        data=Objects.loc[Objects['filename']==filename],\n",
    "        x='barycenter_x',\n",
    "        y='barycenter_y',\n",
    "        hue='position_PD__binned_20',\n",
    "        palette='seismic',\n",
    "        s=0.05, linewidth=0, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot cell properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.violinplot(data=Objects, x='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = dict({\n",
    "    # 'area': True,\n",
    "    # 'area_log': True,\n",
    "    # 'hexatic': True,\n",
    "    # 'neighbour': True,\n",
    "    'id': True,\n",
    "    # 'elongation': True,\n",
    "    # 'elongation_orientation': True,\n",
    "    # 'HCA': True,\n",
    "    # 'HCA_polarity': True,\n",
    "    # 'HCA_polarity_vs_elongation_orientation': True,\n",
    "})\n",
    "\n",
    "print(filenames)\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "\n",
    "    _labels = Labels[filename]\n",
    "    _image = Images[filename]\n",
    "    if 'z' in _image.dims:\n",
    "        _image = _image.max(dim='z')\n",
    "    _image.attrs = Images[filename].attrs\n",
    "    _voronoi = Voronoi[filename]\n",
    "\n",
    "    res_x = _image.attrs['resolution_x']\n",
    "    res_y = _image.attrs['resolution_y']\n",
    "    aspect = res_x / res_y\n",
    "    extent=[0, _image.shape[0]/res_x, 0, _image.shape[1]/res_y]\n",
    "    print(f\"{_image.attrs['resolution_scale']}: {res_x} x {res_y} ({aspect})\")\n",
    "    if not np.isfinite(aspect):\n",
    "        raise\n",
    "    \n",
    "    if not Objects.loc[Objects['filename'] == filename].empty:\n",
    "        objects = Objects.loc[Objects['filename'] == filename].sort_values(by='id').set_index('id').reset_index()\n",
    "        objects = objects.loc[~np.asarray(objects['exclude'], dtype=bool)]\n",
    "\n",
    "        print(objects.to_string())\n",
    "\n",
    "    if True:\n",
    "        _area_map = xr.zeros_like(_labels, dtype=float)\n",
    "        _hexatic_map = xr.zeros_like(_labels, dtype=float)\n",
    "        _neighbour_map = xr.zeros_like(_labels, dtype=float)\n",
    "        _id_map = xr.zeros_like(_labels, dtype=float)\n",
    "        _elongation_map = xr.zeros_like(_labels, dtype=float)\n",
    "        _orientation_map = xr.zeros_like(_labels, dtype=float)\n",
    "        _HCA_map = xr.zeros_like(_labels, dtype=float)\n",
    "        _HCA_polarity = xr.zeros_like(_labels, dtype=float)\n",
    "        _HCA_polarity_amplitude = xr.zeros_like(_labels, dtype=float)\n",
    "        _HCA_polarity_vs_elongation_orientation = xr.zeros_like(_labels, dtype=float)\n",
    "\n",
    "\n",
    "        isExist = os.path.exists(os.path.join(basepath, path, filename[:-4]))\n",
    "        if not isExist:\n",
    "            os.makedirs(os.path.join(basepath, path, filename[:-4]))\n",
    "\n",
    "        isExist = os.path.exists(os.path.join(basepath, path, filename[:-4], \"area\"))\n",
    "        if not isExist:\n",
    "            os.makedirs(os.path.join(basepath, path, filename[:-4], \"area\"))\n",
    "\n",
    "        isExist = os.path.exists(os.path.join(basepath, path, filename[:-4], \"hexatic_order\"))\n",
    "        if not isExist:\n",
    "            os.makedirs(os.path.join(basepath, path, filename[:-4], \"hexatic_order\"))\n",
    "\n",
    "        isExist = os.path.exists(os.path.join(basepath, path, filename[:-4], \"neighbours\"))\n",
    "        if not isExist:\n",
    "            os.makedirs(os.path.join(basepath, path, filename[:-4], \"neighbours\"))\n",
    "\n",
    "        i = 0\n",
    "        step_x = 500\n",
    "        step_y = 250\n",
    "        for x in range(0, _image.shape[0], step_x):\n",
    "            for y in range(0, _image.shape[1], step_y):\n",
    "                i += 1\n",
    "                \n",
    "                image = _image.isel(\n",
    "                    x=slice(x, np.min([x+step_x, _image.shape[0]])),\n",
    "                    y=slice(y, np.min([y+step_y, _image.shape[1]]))\n",
    "                )\n",
    "                labels = _labels.isel(\n",
    "                    x=slice(x, np.min([x+step_x, _image.shape[0]])),\n",
    "                    y=slice(y, np.min([y+step_y, _image.shape[1]]))\n",
    "                )\n",
    "\n",
    "                area_map = xr.zeros_like(labels) * np.nan\n",
    "                hexatic_map = xr.zeros_like(labels) * np.nan\n",
    "                neighbour_map = xr.zeros_like(labels) * np.nan\n",
    "                id_map = xr.zeros_like(labels) * np.nan\n",
    "                elongation_map = xr.zeros_like(labels) * np.nan\n",
    "                orientation_map = xr.zeros_like(labels) * np.nan\n",
    "                HCA_map = xr.zeros_like(labels) * np.nan\n",
    "                HCA_polarity = xr.zeros_like(labels) * np.nan\n",
    "                HCA_polarity_amplitude = xr.zeros_like(labels, dtype=float)\n",
    "                HCA_polarity_vs_elongation_orientation = xr.zeros_like(labels, dtype=float) * np.nan\n",
    "\n",
    "                for id in np.unique(labels):\n",
    "                    if not objects.loc[objects['id']==id].empty:\n",
    "                        object = objects.loc[objects['id']==id].iloc[0]\n",
    "                        if plot.get('area', False) or plot.get('area_log', False):\n",
    "                            area_map = area_map.where(labels != id, object['area'])\n",
    "                        if plot.get('hexatic', False):\n",
    "                            hexatic_map = hexatic_map.where(labels != id, object['hexatic_order'])\n",
    "                        if plot.get('neighbour', False):\n",
    "                            neighbour_map = neighbour_map.where(labels != id, object['num_neighbors_voronoi'])\n",
    "                        if plot.get('id', False):\n",
    "                            id_map = id_map.where(labels != id, id%20+1)\n",
    "                        if plot.get('elongation', False):\n",
    "                            elongation_map = elongation_map.where(labels != id, object['elongation'])\n",
    "                        if plot.get('elongation_orientation', False):\n",
    "                            orientation_map = orientation_map.where(labels != id, object['elongation_orientation'] - object['curvature_tangent_orientation'])\n",
    "                        if plot.get('HCA', False):\n",
    "                            HCA_map = HCA_map.where(labels != id, image / image.where(labels == id).max())\n",
    "                        if plot.get('HCA_polarity', False):\n",
    "                            HCA_polarity = HCA_polarity.where(labels != id, object['HCA_polarity_orientation'] - object['curvature_tangent_orientation'])\n",
    "                            HCA_polarity_amplitude = HCA_polarity_amplitude.where(labels != id, object['HCA_polarity'])\n",
    "                        if plot.get('HCA_polarity_vs_elongation_orientation', False):\n",
    "                            val = np.mod(object['HCA_polarity_orientation'] - object['elongation_orientation'] + math.pi, math.pi)\n",
    "                            HCA_polarity_vs_elongation_orientation = HCA_polarity_vs_elongation_orientation.where(labels != id, val)\n",
    "                            \n",
    "\n",
    "                _area_map.data[x:x+step_x, y:y+step_y] += area_map.data\n",
    "                _hexatic_map.data[x:x+step_x, y:y+step_y] += hexatic_map.data\n",
    "                _neighbour_map.data[x:x+step_x, y:y+step_y] += neighbour_map.data\n",
    "                _id_map.data[x:x+step_x, y:y+step_y] += id_map.data\n",
    "                _elongation_map.data[x:x+step_x, y:y+step_y] += elongation_map.data\n",
    "                _orientation_map.data[x:x+step_x, y:y+step_y] += orientation_map.data\n",
    "                _HCA_map.data[x:x+step_x, y:y+step_y] += HCA_map.data\n",
    "                _HCA_polarity.data[x:x+step_x, y:y+step_y] += HCA_polarity.data\n",
    "                _HCA_polarity_amplitude.data[x:x+step_x, y:y+step_y] += HCA_polarity_amplitude.data\n",
    "                _HCA_polarity_vs_elongation_orientation.data[x:x+step_x, y:y+step_y] += HCA_polarity_vs_elongation_orientation.data\n",
    "\n",
    "        _orientation_map = np.mod(_orientation_map + math.pi, math.pi) - math.pi/2.\n",
    "        _HCA_polarity = np.mod(_HCA_polarity + 2 * math.pi, 2 * math.pi) - math.pi\n",
    "        _HCA_polarity_vs_elongation_orientation = math.pi / 2. - np.abs(math.pi/2. - np.absolute(_HCA_polarity_vs_elongation_orientation))\n",
    "\n",
    "    figsize = _image.shape[0] / _image.shape[1]\n",
    "\n",
    "    if plot.get('area', False):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(aspect)\n",
    "\n",
    "        ax.imshow(_image.T, interpolation='none', cmap='gray', extent=extent)\n",
    "        im = ax.imshow(_area_map.T, interpolation='none', cmap='RdYlBu', alpha=0.65, vmin=0, vmax=objects['area'].max(), extent=extent)\n",
    "        fig.colorbar(im, ax=ax, label=f'Apical area [$\\mu m^2$]')\n",
    "\n",
    "        ax.set_xlabel('P-D axis [$\\mu m$]')\n",
    "        ax.set_ylabel('S-I axis [$\\mu m$]')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"area.svg\"),format='svg')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"area.png\"), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "    if plot.get('area_log', False):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(aspect)\n",
    "\n",
    "        ax.imshow(_image.T, interpolation='none', cmap='gray', extent=extent)\n",
    "        im = ax.imshow(\n",
    "            _area_map.T, \n",
    "            interpolation='none', \n",
    "            cmap='gist_rainbow', \n",
    "            alpha=0.65, \n",
    "            norm=mpl.colors.LogNorm(vmin=4, vmax=40),\n",
    "            extent=extent\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel('P-D axis [$\\mu m$]')\n",
    "        ax.set_ylabel('S-I axis [$\\mu m$]')\n",
    "        fig.colorbar(im, ax=ax, label=f'Apical area [$\\mu m^2$]', ticks=[5, 10, 20, 40])\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"area_log.svg\"),format='svg')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"area_log.png\"), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    if plot.get('hexatic', False):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(aspect)\n",
    "        \n",
    "        ax.imshow(_image.T, interpolation='none', cmap='gray', extent=extent)\n",
    "        im = ax.imshow(_hexatic_map.T, interpolation='none', cmap='seismic', vmin=0, vmax=0.8, alpha=0.65, extent=extent)\n",
    "        fig.colorbar(im, ax=ax, label='Hexatic order')\n",
    "\n",
    "\n",
    "        ax.set_xlabel('P-D axis [$\\mu m$]')\n",
    "        ax.set_ylabel('S-I axis [$\\mu m$]')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"hexatic_order.svg\"),format='svg')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"hexatic_order.png\"), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    if plot.get('neighbour', False):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(aspect)\n",
    "        \n",
    "        ax.imshow(_image.T, interpolation='none', cmap='gray', extent=extent)\n",
    "        im = ax.imshow(_neighbour_map.T, interpolation='none', cmap='seismic', vmin=3, vmax=9, alpha=0.65, extent=extent)\n",
    "        fig.colorbar(im, ax=ax, label='Neighbour number')\n",
    "\n",
    "\n",
    "        ax.set_xlabel('P-D axis [$\\mu m$]')\n",
    "        ax.set_ylabel('S-I axis [$\\mu m$]')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"neighbours.svg\"),format='svg')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"neighbours.png\"), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    if plot.get('id', False):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(aspect)\n",
    "        \n",
    "        ax.imshow(_image.T, interpolation='none', cmap='gray', extent=extent)\n",
    "        im = ax.imshow(_id_map.where(_id_map > 0).T, interpolation='none', cmap='tab20', alpha=0.85, extent=extent)\n",
    "        fig.colorbar(im, ax=ax, label='Segmented')\n",
    "\n",
    "\n",
    "        ax.set_xlabel('P-D axis [$\\mu m$]')\n",
    "        ax.set_ylabel('S-I axis [$\\mu m$]')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"identified.svg\"),format='svg')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"identified.png\"), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    if plot.get('elongation', False):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(aspect)\n",
    "        \n",
    "        ax.imshow(_image.T, interpolation='none', cmap='gray', extent=extent)\n",
    "        im = ax.imshow(_elongation_map.T, interpolation='none', cmap='Reds', alpha=0.85, vmin=0, extent=extent)\n",
    "        fig.colorbar(im, ax=ax, label='Elongation')\n",
    "\n",
    "        ax.set_xlabel('P-D axis [$\\mu m$]')\n",
    "        ax.set_ylabel('S-I axis [$\\mu m$]')\n",
    "\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"elongation.svg\"),format='svg')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"elongation.png\"), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    if plot.get('elongation_orientation', False):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(aspect)\n",
    "        \n",
    "        ax.imshow(_image.T, interpolation='none', cmap='gray', extent=extent)\n",
    "        im = ax.imshow(_orientation_map.T, interpolation='none', cmap='hsv', alpha=0.85, vmin=-math.pi/2., vmax=math.pi/2., extent=extent)\n",
    "        cbar = fig.colorbar(im, ax=ax, label='Orientation of elongation', ticks=[-math.pi/2., 0,  math.pi/2.])\n",
    "        cbar.ax.set_yticklabels(['Proximally - Distally', 'Inferiorly - Superiorly', 'Proximally - Distally'])\n",
    "\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"elongation_orientation.svg\"),format='svg')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"elongation_orientation.png\"), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    if plot.get('HCA', False):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(aspect)\n",
    "        \n",
    "        scale = (objects['area_pixels']/math.pi)**0.5\n",
    "\n",
    "        ax.imshow(_image.T, interpolation='none', cmap='gray', extent=extent)\n",
    "        im = ax.imshow(_HCA_map.T, interpolation='none', cmap='inferno', vmin=0, vmax=1., extent=extent)\n",
    "        fig.colorbar(im, ax=ax, label='local HCA profile')\n",
    "\n",
    "        ax.set_xlabel('P-D axis [$\\mu m$]')\n",
    "        ax.set_ylabel('S-I axis [$\\mu m$]')\n",
    "        ax.quiver(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'],\n",
    "                scale * objects['HCA_polarity_px'], scale * objects['HCA_polarity_py'],\n",
    "                angles='xy', scale_units='xy', scale=1./_image.attrs['resolution_x']**2, \n",
    "                color='green', width=0.00033, headwidth=1, headlength=1\n",
    "                )\n",
    "\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"HCA_profile.svg\"),format='svg')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"HCA_profile.png\"), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    if plot.get('HCA_polarity', False):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(aspect)\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        scale = (objects['area_pixels']/math.pi)**0.5\n",
    "\n",
    "        _HCA_polarity_amplitude = (_HCA_polarity_amplitude - _HCA_polarity_amplitude.min()) / (_HCA_polarity_amplitude.max() - _HCA_polarity_amplitude.min())\n",
    "\n",
    "        ax.imshow(_image.T, interpolation='none', cmap='gray', extent=extent)\n",
    "        im = ax.imshow(_HCA_polarity.T, interpolation='none', cmap='hsv', vmin=-math.pi, vmax=math.pi, alpha=_HCA_polarity_amplitude.T, extent=extent)\n",
    "        cbar = fig.colorbar(im, ax=ax, label='HCA orientation', ticks=[-math.pi, -math.pi/2., 0,  math.pi/2., math.pi])\n",
    "        cbar.ax.set_yticklabels(['Distally', 'Inferiorly', 'Proximally', 'Superiorly', 'Distally'])\n",
    "\n",
    "        ax.set_xlabel('P-D axis [$\\mu m$]')\n",
    "        ax.set_ylabel('S-I axis [$\\mu m$]')\n",
    "\n",
    "        ax.quiver(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'],\n",
    "                scale * objects['HCA_polarity_px'], scale * objects['HCA_polarity_py'],\n",
    "                angles='xy', scale_units='xy', scale=1./_image.attrs['resolution_x']**2, \n",
    "                color='white', width=0.00033, headwidth=1, headlength=1\n",
    "                )\n",
    "\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"HCA_polarity.svg\"),format='svg')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"HCA_polarity.png\"), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(aspect)\n",
    "        \n",
    "        scale = (objects['area_pixels']/math.pi)**0.5\n",
    "\n",
    "        _HCA_polarity_amplitude = (_HCA_polarity_amplitude - _HCA_polarity_amplitude.min()) / (_HCA_polarity_amplitude.max() - _HCA_polarity_amplitude.min())\n",
    "\n",
    "        ax.imshow(_image.T, interpolation='none', cmap='gray', extent=extent)\n",
    "        im = ax.imshow(_HCA_polarity.T, interpolation='none', cmap='hsv', vmin=-math.pi, vmax=math.pi, extent=extent)\n",
    "        cbar = fig.colorbar(im, ax=ax, label='HCA orientation', ticks=[-math.pi, -math.pi/2., 0,  math.pi/2., math.pi])\n",
    "        cbar.ax.set_yticklabels(['Distally', 'Inferiorly', 'Proximally', 'Superiorly', 'Distally'])\n",
    "\n",
    "        ax.set_xlabel('P-D axis [$\\mu m$]')\n",
    "        ax.set_ylabel('S-I axis [$\\mu m$]')\n",
    "\n",
    "        ax.quiver(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'],\n",
    "                scale * objects['HCA_polarity_px'], scale * objects['HCA_polarity_py'],\n",
    "                angles='xy', scale_units='xy', scale=1./_image.attrs['resolution_x']**2, \n",
    "                color='white', width=0.00033, headwidth=1, headlength=1\n",
    "                )\n",
    "\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"HCA_polarity__.svg\"),format='svg')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"HCA_polarity__.png\"), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "    if plot.get('HCA_polarity_vs_elongation_orientation', False):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(aspect)\n",
    "        \n",
    "\n",
    "        _HCA_polarity_amplitude = (_HCA_polarity_amplitude - _HCA_polarity_amplitude.min()) / (_HCA_polarity_amplitude.max() - _HCA_polarity_amplitude.min())\n",
    "\n",
    "        ax.imshow(_image.T, interpolation='none', cmap='gray', extent=extent)\n",
    "        im = ax.imshow(_HCA_polarity_vs_elongation_orientation.T, interpolation='none', cmap='Reds', extent=extent) # , vmin=0, vmax=math.pi)\n",
    "        cbar = fig.colorbar(im, ax=ax, label='Diff. HCA polarity vs elongation')\n",
    "\n",
    "        ax.set_xlabel('P-D axis [$\\mu m$]')\n",
    "        ax.set_ylabel('S-I axis [$\\mu m$]')\n",
    "\n",
    "        scale = objects['elongation'] * (objects['area_pixels']/math.pi)**0.5\n",
    "        ax.quiver(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'],\n",
    "                scale * np.cos(objects['elongation_orientation']), scale * np.sin(objects['elongation_orientation']),\n",
    "                angles='xy', scale_units='xy', scale=1./_image.attrs['resolution_x']**2, pivot='mid',\n",
    "                color='black', width=0.00033, headwidth=1, headlength=0\n",
    "                )\n",
    "        scale = (objects['area_pixels']/math.pi)**0.5\n",
    "        ax.quiver(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'],\n",
    "                scale * objects['HCA_polarity_px'], scale * objects['HCA_polarity_py'],\n",
    "                angles='xy', scale_units='xy', scale=1./_image.attrs['resolution_x']**2, \n",
    "                color='magenta', width=0.00033, headwidth=1, headlength=1\n",
    "                )\n",
    "\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"HCA_polarity_vs_elongation_orientation.svg\"),format='svg')\n",
    "        fig.savefig(os.path.join(basepath, path, filename[:-4], f\"HCA_polarity_vs_elongation_orientation.png\"), dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "_labels=None\n",
    "del _labels\n",
    "_image=None\n",
    "del _image\n",
    "_voronoi=None\n",
    "del _voronoi\n",
    "objects=None\n",
    "del objects\n",
    "_area_map = None\n",
    "del _area_map\n",
    "_hexatic_map = None\n",
    "del _hexatic_map\n",
    "_neighbour_map = None\n",
    "del _neighbour_map\n",
    "_id_map = None\n",
    "del _id_map\n",
    "_elongation_map = None\n",
    "del _elongation_map\n",
    "_orientation_map = None\n",
    "del _orientation_map\n",
    "_HCA_map=None\n",
    "del _HCA_map\n",
    "_HCA_polarity=None\n",
    "del _HCA_polarity\n",
    "_HCA_polarity_amplitude=None\n",
    "del _HCA_polarity_amplitude\n",
    "area_map = None\n",
    "del area_map\n",
    "hexatic_map = None\n",
    "del hexatic_map\n",
    "neighbour_map = None\n",
    "del neighbour_map\n",
    "id_map = None\n",
    "del id_map\n",
    "elongation_map = None\n",
    "del elongation_map\n",
    "orientation_map = None\n",
    "del orientation_map\n",
    "HCA_map=None\n",
    "del HCA_map\n",
    "HCA_polarity=None\n",
    "del HCA_polarity\n",
    "HCA_polarity_amplitude=None\n",
    "del HCA_polarity_amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.histplot(Objects, x='HCA_polarity')\n",
    "Objects['HCA_polarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = skimage.filters.threshold_otsu(img)\n",
    "print(thresh)\n",
    "\n",
    "bw = np.where(img > thresh, img, 0)\n",
    "bw = skimage.morphology.binary_dilation(bw)\n",
    "# bw = skimage.morphology.binary_erosion(bw)\n",
    "print(bw)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=[10, 10])\n",
    "ax.set_aspect(1)\n",
    "ax.imshow(bw.T, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.hist(img.flatten(), bins=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to separate the two objects in image\n",
    "# Generate the markers as local maxima of the distance to the background\n",
    "\n",
    "bw = bw > 0\n",
    "\n",
    "distance = scipy.ndimage.distance_transform_edt(bw)\n",
    "coords = skimage.feature.peak_local_max(distance, labels=bw, min_distance=5)\n",
    "mask = np.zeros(distance.shape, dtype=bool)\n",
    "mask[tuple(coords.T)] = True\n",
    "markers, _ = scipy.ndimage.label(mask)\n",
    "labels = skimage.segmentation.watershed(-distance, markers, mask=bw)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[25, 10])\n",
    "ax1.set_aspect(1)\n",
    "ax2.set_aspect(1)\n",
    "ax3.set_aspect(1)\n",
    "ax1.imshow(img_.T, cmap='gray')\n",
    "ax3.imshow(distance.T, cmap='gray')\n",
    "ax1.scatter(coords[:, 0], coords[:, 1], s=1)\n",
    "ax2.scatter(coords[:, 0], coords[:, 1], s=1)\n",
    "ax3.scatter(coords[:, 0], coords[:, 1], s=1)\n",
    "# ax2.invert_yaxis()\n",
    "\n",
    "ax2.imshow(np.where(labels > 0, labels, np.nan).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=[10, 10])\n",
    "ax.set_aspect(1)\n",
    "ax.imshow(img_.where(labels > 0).T, cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # analyse the objects\n",
    "# objects = pd.DataFrame()\n",
    "# for id in np.unique(labels):\n",
    "#     if id == 0: \n",
    "#         continue\n",
    "    \n",
    "#     # the coordinate axes\n",
    "#     argwhere = np.argwhere((labels == id).data)\n",
    "#     argwhere = np.asarray(argwhere, dtype=float)\n",
    "    \n",
    "#     # calculate in pixel dimensions\n",
    "#     barycenter = argwhere.mean(0)\n",
    "#     max = argwhere.max(0)\n",
    "#     min = argwhere.min(0)\n",
    "\n",
    "#     if min[0] == 0 or min[1] == 0 or max[0] >= len(img_.x)-1 or max[1] >= len(img_.y)-1:\n",
    "#         continue\n",
    "\n",
    "#     mask = np.where(labels == id, 1, 0)\n",
    "#     volume = mask.sum()\n",
    "\n",
    "#     objects.loc[id, 'volume_pixels'] = volume\n",
    "#     for i, axis in enumerate(['x', 'y']):\n",
    "#         objects.loc[id, 'barycenter_{}_pixels'.format(axis)] = barycenter[i]\n",
    "#     for i, axis in enumerate(['x', 'y']):\n",
    "#         objects.loc[id, 'min_{}_pixels'.format(axis)] = min[i]\n",
    "#         objects.loc[id, 'max_{}_pixels'.format(axis)] = max[i]\n",
    "\n",
    "\n",
    "# # use image resolution\n",
    "# res_x = img_.attrs['resolution_x']\n",
    "# res_y = img_.attrs['resolution_y']\n",
    "# res_z = img_.attrs['resolution_z']\n",
    "\n",
    "# objects['volume'] = objects['volume_pixels'] / res_x / res_y\n",
    "\n",
    "# objects['barycenter_x'] = objects['barycenter_x_pixels'] / res_x\n",
    "# objects['barycenter_y'] = objects['barycenter_y_pixels'] / res_y\n",
    "\n",
    "# objects['min_x'] = objects['min_x_pixels'] / res_x\n",
    "# objects['max_x'] = objects['max_x_pixels'] / res_x\n",
    "# objects['min_y'] = objects['min_y_pixels'] / res_y\n",
    "# objects['max_y'] = objects['max_y_pixels'] / res_y\n",
    "\n",
    "# print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for x in range(0, img.shape[0], 500):\n",
    "    for y in range(0, img.shape[1], 250):\n",
    "        if img[x:x+500, y:y+250].mean() < 0.005:\n",
    "            continue\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[20, 20 / figsize])\n",
    "        ax.set_aspect(1)\n",
    "        ax.imshow(np.where(labels > 0, 1, 0.5).T * img_.T, cmap='gray')\n",
    "        # ax.imshow(np.where(labels > 0, 1, 0).T, cmap='gray')\n",
    "\n",
    "        # ax.scatter(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'], s=1)\n",
    "        ax.scatter(coords[:, 0], coords[:, 1])\n",
    "\n",
    "        ax.set_xlim(x, x+500)\n",
    "        ax.set_ylim(y, y+250)\n",
    "\n",
    "\n",
    "        fig.savefig(os.path.join(basepath, path, filenames[0][:-4], f\"crop_{i}.png\"))\n",
    "        i += 1\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=[10, 10])\n",
    "ax.set_aspect(1)\n",
    "ax.imshow(np.where(labels > 0, 1, 0.5).T * img_.T, cmap='gray')\n",
    "# ax.imshow(np.where(labels > 0, 1, 0).T, cmap='gray')\n",
    "\n",
    "# ax.scatter(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'], s=1)\n",
    "ax.scatter(coords[:, 0], coords[:, 1])\n",
    "\n",
    "ax.set_xlim(200, 400)\n",
    "ax.set_ylim(2300, 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=[10, 10])\n",
    "ax.set_aspect(1)\n",
    "ax.imshow(np.where(labels > 0, 1, 0.5).T * img_.T, cmap='gray')\n",
    "# ax.imshow(np.where(labels > 0, 1, 0).T, cmap='gray')\n",
    "\n",
    "# ax.scatter(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'], s=1)\n",
    "ax.scatter(coords[:, 0], coords[:, 1])\n",
    "\n",
    "ax.set_xlim(1000, 1200)\n",
    "ax.set_ylim(1900, 2100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=[10, 10])\n",
    "ax.set_aspect(1)\n",
    "ax.imshow(np.where(labels > 0, 1, 0.5).T * img_.T, cmap='gray')\n",
    "# ax.imshow(np.where(labels > 0, 1, 0).T, cmap='gray')\n",
    "\n",
    "# ax.scatter(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'], s=1)\n",
    "ax.scatter(coords[:, 0], coords[:, 1])\n",
    "\n",
    "ax.set_xlim(2000, 2200)\n",
    "ax.set_ylim(1600, 1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=[10, 10])\n",
    "ax.set_aspect(1)\n",
    "ax.imshow(np.where(labels > 0, 1, 0.5).T * img_.T, cmap='gray')\n",
    "# ax.imshow(np.where(labels > 0, 1, 0).T, cmap='gray')\n",
    "\n",
    "# ax.scatter(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'], s=1)\n",
    "ax.scatter(coords[:, 0], coords[:, 1])\n",
    "\n",
    "ax.set_xlim(3000, 3200)\n",
    "ax.set_ylim(1400, 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=[10, 10])\n",
    "ax.set_aspect(1)\n",
    "ax.imshow(np.where(labels > 0, 1, 0.5).T * img_.T, cmap='gray')\n",
    "# ax.imshow(np.where(labels > 0, 1, 0).T, cmap='gray')\n",
    "\n",
    "# ax.scatter(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'], s=1)\n",
    "ax.scatter(coords[:, 0], coords[:, 1])\n",
    "\n",
    "ax.set_xlim(4000, 4200)\n",
    "ax.set_ylim(1100, 1300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=[10, 10])\n",
    "ax.set_aspect(1)\n",
    "ax.imshow(np.where(labels > 0, 1, 0.5).T * img_.T, cmap='gray')\n",
    "# ax.imshow(np.where(labels > 0, 1, 0).T, cmap='gray')\n",
    "\n",
    "# ax.scatter(objects['barycenter_x_pixels'], objects['barycenter_y_pixels'], s=1)\n",
    "ax.scatter(coords[:, 0], coords[:, 1])\n",
    "\n",
    "ax.set_xlim(5000, 5200)\n",
    "ax.set_ylim(1300, 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "print(N*12)\n",
    "x = np.linspace(0, N, 500)\n",
    "\n",
    "l = 4\n",
    "r = 0.5\n",
    "def A(x):\n",
    "    # return (l - r) * np.cos(math.pi/2 * x / N) + r\n",
    "    return (l - r) * np.cos(math.pi /2 * x/N)**2 + r\n",
    "\n",
    "def radius(x):\n",
    "    return (A(x) / math.pi)**0.5\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, sharex=True, figsize=[4, 4])\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0].plot(x, A(x))\n",
    "axes[0].plot(x, A(x-2*radius(x)), ls=':')\n",
    "axes[0].plot(x, A(x+2*radius(x)), ls=':')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(x, (A(x-2*radius(x)) - A(x+2*radius(x))))\n",
    "axes[1].plot(x, (A(x-2*radius(x)) - A(x+2*radius(x)))/A(x), label='relative')\n",
    "axes[1].legend()\n",
    "\n",
    "axes[0].set_ylabel(\"Area\")\n",
    "axes[1].set_ylabel(\"Area difference\")\n",
    "\n",
    "axes[0].set_xlim(0, N)\n",
    "axes[0].set_ylim(0, 4)\n",
    "axes[1].set_ylim(0, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
